#+begin_src latex
  \section{Introduction}
  The design of diagnostic PCR primers is often hampered by an excess of
  candidates that also amplify off-target regions. To minimize the
  chance of cross-amplification, primers should be designed from
  template sequences that are unique to the target strain. The program
  \texttt{fur} \emph{finds unique regions} by comparing the genomes of a
  sample of target strains to the genomes of the closest relatives the
  targets are to be distinguished from. The underlying heuristic is that
  any region that distinguishes a target from its closest relatives,
  also distinguishes it from all other sequences out there.

  Consider, for example, \textit{Escherichia coli} ST131, a multi-drug
  resistant strain that causes urinary tract and blood infections in
  humans~\cite{pet14:glo}. \emph{E. coli} ST131 belongs to the B2
  phylogenetic subgroup, which corresponds to serotype O25b:H4.
  Figure~\ref{fig:eco} shows the phylogeny of 105 \emph{E. coli} B2
  strains. The clade marked ST131 comprises 95 strains newly sequenced
  by~\cite{pet14:glo}, plus three STS131 reference genomes, SE15, NA114,
  and EC958. This clade defines the \emph{targets} marked $\mathcal{T}$
  in Figure~\ref{fig:eco}. The seven remaining
  \emph{E. coli} strains are the \emph{neighbors}, $\mathcal{N}$. They also
  belong to the B2 group, but not to ST131~\cite{pet14:glo}. The aim is
  to find regions specific to ST131. In Section~\ref{sec:tut} a
  tutorial-style analysis of this data set shows how to do this
  using \texttt{fur}.

      \begin{figure}
	\begin{center}
	  \tiny
	  \resizebox{\textwidth}{!}{\input{eco105}}
	\end{center}
	\caption{Phylogeny of 105 strains of \emph{Eschericia coli}
	  computed from whole genome sequences using
	  \texttt{andi}~\cite{hau15:and}. The scale bar is the number of
	  substitutions per site. The clade marked ST131 contains the
	  pathogenic targets ($\mathcal{T}$), the remaining seven
	  strains are the neighbors ($\mathcal{N}$).}\label{fig:eco}
      \end{figure}

  The program takes as input a database computed by
  \texttt{makeFurDb}\footnote{\texttt{https://github.com/haubold/makeFurDb/}}
  from two directories of sequence files, the first contains one or more
  target genomes, the second one or more neighbor genomes. \texttt{fur}
  uses \texttt{macle}~\cite{pir18:hig} to identify candidate regions
  that are unique to a representative target when compared to all
  neighbors. These candidate regions are then checked for presence in
  all targets and absence from all neighbors using BLAST. The resulting
  templates are finally printed to screen. They are now ready for
  submission to a primer design program like
  Primer-BLAST~\cite{ye12:pri}.

  \section{Implementation}
  The program is based on arrays of sequences and arrays of intervals on
  those sequences. Arrays of sequences are defined in \texttt{seq.h},
  while intervals and their arrays are still to be defined. Apart from
  data structures for intervals and their arrays, the program consists
  of the usual include section, declarations and definitions of
  functions, and finally the \texttt{main} function.
#+end_src
#+begin_src C <<fur.c>>=
  #include "seq.h"
  //<<Include headers>>
  //<<Data structures>>
  //<<Function declarations>>
  //<<Function definitions>>
  //<<Main function>>
#+end_src
#+begin_src latex
  \subsection{Arrays of Sequences and of Intervals}
  Interval arrays are one of the the basic building blocks of
  \texttt{fur}, so they are defined first. Intervals have a start and an
  end.
#+end_src
#+begin_src C <<Data structures>>=
  typedef struct intv {
    int s, e;
  } Intv;
#+end_src
#+begin_src latex
  An arbitrary number of $n$ intervals is stored in an interval array.
#+end_src
#+begin_src C <<Data structures>>=
  typedef struct intvArr {
    Intv **arr;
    int n;
  } IntvArr;
#+end_src
#+begin_src latex
  Interval arrays require functions for construction, freeing, and
  addition. Construction is declared with start and end positions
  supplied as parameters.
#+end_src
#+begin_src C <<Function declarations>>=
  Intv *newIntv(int s, int e);
#+end_src
#+begin_src latex
  These positions are saved once space has been made for them.
#+end_src
#+begin_src C <<Function definitions>>=
  Intv *newIntv(int s, int e) {
    Intv *i = (Intv *)emalloc(sizeof(Intv));
    i->s = s;
    i->e = e;
    return i;
  }
#+end_src
#+begin_src latex
  The function \texttt{emalloc} is declared in \texttt{error.h}.
#+end_src
#+begin_src C <<Include headers>>=
  #include "error.h"
#+end_src
#+begin_src latex
  Next, the construction of an interval array is declared.
#+end_src
#+begin_src C <<Function declarations>>=
  IntvArr *newIntvArr();
#+end_src
#+begin_src latex
  Its definition returns an empty array of intervals.
#+end_src
#+begin_src C <<Function definitions>>=
  IntvArr *newIntvArr() {
    IntvArr *ia = (IntvArr *)emalloc(sizeof(IntvArr));
    ia->arr = NULL;
    ia->n = 0;
    return ia;
  }
#+end_src
#+begin_src latex
  And to deconstruct, the freeing of an interval array is declared.
#+end_src
#+begin_src C <<Function declarations>>=
  void freeIntvArr(IntvArr *ia);
#+end_src
#+begin_src latex
  Its definition frees each interval in turn before freeing the interval
  array itself.
#+end_src
#+begin_src C <<Function definitions>>=
  void freeIntvArr(IntvArr *ia) {
    for (int i = 0; i < ia->n; i++)
      free(ia->arr[i]);
    free(ia->arr);
    free(ia);
  }
#+end_src
#+begin_src latex
  Declare the addition of an interval to an existing interval array.
#+end_src
#+begin_src C <<Function declarations>>=
  void intvArrAdd(IntvArr *ia, Intv *i);
#+end_src
#+begin_src latex
  The definition makes space for the newly arrived interval and then
  adds it.
#+end_src
#+begin_src C <<Function definitions>>=
  void intvArrAdd(IntvArr *ia, Intv *i) {
    ia->arr = (Intv **)
      erealloc(ia->arr, (ia->n + 1) * sizeof(Intv *));
    ia->arr[ia->n++] = i;
  }
#+end_src
#+begin_src latex
  \subsection{Sequence Analysis}
  Interval arrays are now ready to be used. This is done in the
  \texttt{main} function, which first interacts with the user, then
  analyzes the targets and neighbors, and finally prints the desired
  templates. At the end of the program any memory still allocated is
  freed.
#+end_src
#+begin_src C <<Main function>>=
  int main(int argc, char **argv) {
    // <<Interact with user>>
    // <<Analyze sequences>>
    // <<Print templates>>
    // <<Free memory>>
  }
#+end_src
#+begin_src latex
  \subsubsection{User Interaction}
  Whenever the program interacts with the user, it identifies itself, so
  its name is set.
#+end_src
#+begin_src C <<Interact with user>>=
  setprogname(argv[0]);
#+end_src
#+begin_src latex
  The function \texttt{setprogname} is declared in the standard part of
  the BSD library.
#+end_src
#+begin_src C <<Include headers>>=
  #include <bsd/stdlib.h>
#+end_src
#+begin_src latex
  The user interaction is mediated via a container holding the options
  and their arguments.
#+end_src
#+begin_src C <<Interact with user>>=
  Args *args = getArgs(argc, argv);
#+end_src
#+begin_src latex
  The \texttt{Args} data structure and the \texttt{getArgs} function are
  declared in \texttt{interface.h}.
#+end_src
#+begin_src C <<Include headers>>=
  #include "interface.h"
#+end_src
#+begin_src latex
  The argument container is freed at the end.
#+end_src
#+begin_src C <<Free memory>>=
  freeArgs(args);
#+end_src
#+begin_src latex
  The options passed via \texttt{args} might include a request for help,
  or indicate an error. In that case, \texttt{printUsage}, which is also
  declared in \texttt{interface.h}, emits a usage message before
  exiting.
#+end_src
#+begin_src C <<Interact with user>>=
  if (args->h || args->err)
    printUsage();
#+end_src
#+begin_src latex
  Alternatively, the user might request information about the program,
  whereupon it makes a modest splash and exits.
#+end_src
#+begin_src C <<Interact with user>>=
  if (args->v)
    printSplash(args);
#+end_src
#+begin_src latex
  \subsubsection{Find Unique Templates}
  Analysis of the targets and neighbors proceeds in two steps. Unique
  regions are first identified by comparing one representative target to
  all neighbors. Then the unique regions are checked for presence in all
  targets and absence from all neighbors.
#+end_src
#+begin_src C <<Analyze sequences>>=
  //<<Identify unique regions>>
  //<<Check presence in all targets>>
  //<<Check absence from all neighbors>>
#+end_src
#+begin_src latex
  Unique regions are identified using the external program
  \texttt{macle}\footnote{\texttt{https://github.com/evolbioinf/macle}}~\cite{pir18:hig}. This
  operates by traversing a pre-computed index. The index is part of the
  \texttt{fur} database and contains the neighbors augmented by the
  representative target. This index is used to compute local complexity
  values for identifying unique intervals.
#+end_src
#+begin_src C <<Identify unique regions>>=
  //<<Get representative target>>
  //<<Construct unique intervals>>
#+end_src
#+begin_src latex
  To obtain the representative target, its name is needed, which allows
  retrieval of its sequence.
#+end_src
#+begin_src C <<Get representative target>>=
  char rn[256];
  Seq *rs = NULL;
  //<<Get representative name>>
  //<<Get representative sequence>>
#+end_src
#+begin_src latex
  The representative name is obtained from the \texttt{macle} index,
  where it is first in the name list. This ordering is ensured by the
  program \texttt{makeFurDb}.
#+end_src
#+begin_src C <<Get representative name>>=
  char *tmpl = "macle -l %s/macle.idx | "
    "head -n 6 | tail -n 1 | "
    "awk '{print $6 }'";
  char cmd[1024];
  sprintf(cmd, tmpl, args->d);
  FILE *pp = epopen(cmd, "r");
  if (fscanf(pp, "%s", rn) == EOF)
    error("couldn't run %s\n", cmd);
  pclose(pp);
#+end_src
#+begin_src latex
  With the sequence name as handle, the corresponding sequence is
  extracted from the BLAST database.
#+end_src
#+begin_src C <<Get representative sequence>>=
  tmpl = "blastdbcmd -entry %s -db %s/blastdb";
  sprintf(cmd, tmpl, rn, args->d);
  pp = epopen(cmd, "r");
  Seq *sp;
  while ((sp = getSeq(pp)) != NULL)
    rs = sp;
  pclose(pp);
#+end_src
#+begin_src latex
  The representative target is freed at the end of the program.
#+end_src
#+begin_src C <<Free memory>>=
  freeSeq(rs);
#+end_src
#+begin_src latex
  To construct unique intervals, the complexity threshold indicating
  uniqueness is computed as preparation for the sliding window analysis
  of local complexity. Figure~\ref{fig:sw} shows a cartoon of a sliding
  window analysis. The overlapping windows returned by \texttt{macle}
  are characterized by their mid-points (dots) and are either unique
  (lightgray) or not (black). The unique windows are summarized into
  unique intervals (dashed). The array of unique intervals is eventually
  converted into an array of unique sequences, the template candidates.

  \begin{figure}
    \begin{center}
      \input{sw}
    \end{center}
    \caption{Sliding window analysis of a genome sequence. The
      overlapping windows are centered on their mid-points (dots) and
      are either unique (lightgray), or not (black). Unique windows are
      summarized into unique intervals (dashed).}\label{fig:sw}
  \end{figure}

#+end_src
#+begin_src C <<Construct unique intervals>>=
  double mc, gc = 0.;
  long len = 0;
  IntvArr *ia;
  //<<Compute complexity threshold>>
  fprintf(stderr, "# Sliding window anlaysis...");
  //<<Sliding window analysis>>
  fprintf(stderr, "done.\n");
  //<<Prepare array of unique sequences>>
#+end_src
#+begin_src latex
  The complexity threshold is a function of aggregate sequence length,
  GC-content, window length, and the inverse of the cumulative
  distribution function (CDF) of the match length null
  distribution. Figure~\ref{fig:cdf} shows this function and how
  choosing a particular CDF-value, on the $y$-axis, 0.95 in the example,
  corresponds to a complexity-threshold on the $x$-axis, 0.019. Sequence
  length and GC content are looked up in the \texttt{macle} index,
  window length and probability supplied by the user.

  \begin{figure}
    \begin{center}
      \scalebox{0.6}{\input{cdf}}
    \end{center}
    \caption{Cumulative distribution function (CDF) of the match
      complexity ($C_{\rm m}$) in 500 bp windows over a 35.5 Mb data set
      with GC-content 0.5~\cite{pir18:hig}. The parameter choice
      corresponds to the neighbors depicted in Figure~\ref{fig:eco}. The
      vertical line indicates the complexity threshold for a cumulative
      value of 0.95.}\label{fig:cdf}
  \end{figure}
#+end_src
#+begin_src C <<Compute complexity threshold>>=
  tmpl = "macle -l %s/macle.idx | "
    "tail -n +2 | "
    "awk '{print $2}'";
  sprintf(cmd, tmpl, args->d);
  pp = epopen(cmd, "r");
  if (fscanf(pp, "%ld", &len) == EOF)
    error("couldn't run %s\n", cmd);
  if (fscanf(pp, "%lf", &gc) == EOF)
    error("couldn't run %s\n", cmd);
  mc = quantCm(len, gc, args->w, args->p);
  pclose(pp);
#+end_src
#+begin_src latex
  The function \texttt{quantCm} is part of the
  \texttt{matchLen}\footnote{\texttt{https://github.com/evolbioinf/matchLen}}
  library.
#+end_src
#+begin_src C <<Include headers>>=
  #include "matchLen.h"
#+end_src
#+begin_src latex
  A sliding window analysis by \texttt{macle} returns pairs of values,
  $(m, C_{\rm m})$, where $m$ is the window midpoint and $C_{\rm m}$ its
  complexity. Let $t$ be the uniqueness threshold. If $C_{\rm m}\ge t$,
  the corresponding window is deemed unique. It also belongs to a unique
  interval of one or more overlapping unique windows. As the algorithm
  parses the windows from left to right, it toggles between being inside
  or outside a unique interval.
#+end_src
#+begin_src C <<Sliding window analysis>>=
  //<<Prepare sliding window analysis>>
  while (fscanf(pp, "%f %f", &m, &c) != EOF) {
    //<<Determine window start and end>>
    if (in) {
      //<<Inside unique interval>>
    } else {
      //<<Outside unique interval>>
    }
  }
  pclose(pp);
#+end_src
#+begin_src latex
  The sliding window analysis requires the opening of a pipe for reading
  \texttt{macle} output. The pipe command consists of three steps. The
  first calls \texttt{macle}, the second cuts the $(m,C_{\rm m})$ pairs
  from the output, and the third removes windows without reliable
  sequence data, where $C_{\rm m}=-1$. In addition, the sliding window
  analysis requires variables for holding the current midpoint and
  complexity values, the interval array, and a variable to indicate
  whether the program is inside a unique interval or not.
#+end_src
#+begin_src C <<Prepare sliding window analysis>>=
  tmpl =
    "macle -i %s/macle.idx -n %s -w %d | "
    "cut -f 2,3 | "
    "awk '$2 > -1'";
  sprintf(cmd, tmpl, args->d, rn, args->w);
  pp = epopen(cmd, "r");
  float m, c;
  ia = newIntvArr();
  int is, ie, in = 0;
#+end_src
#+begin_src latex
  The start and end points of a window are calculated roughly as $m\pm w
  / 2$, where $w$ is the window length. To get the borders exactly
  right, consider a sequence of length 100, for which \texttt{macle}
  prints a mid-point of 50. To recover the correct start and end
  positions of 1 and 100 from this, compute
  \begin{eqnarray*}
    \mbox{start} & = & m - w / 2 + 1\\
    \mbox{end}   & = & m + w / 2
  \end{eqnarray*}                 
  Since positions in strings are zero-based, while \texttt{macle} output
  is one-based, the final start and end values are shifted by one
  position to the left.
#+end_src
#+begin_src C <<Determine window start and end>>=
  int ws = m - args->w / 2;
  int we = m + args->w / 2 - 1;
#+end_src
#+begin_src latex
  If a unique \emph{window} overlaps an existing unique \emph{interval},
  the interval is extended to the right
  (Figure~\ref{fig:sw}). Otherwise, the interval is ``closed'' at the
  endpoint found in the previous round, and added to the interval array.
#+end_src
#+begin_src C <<Inside unique interval>>=
  if (ws <= ie && c >= mc)
    ie = we;
  else {
    in = 0;
    intvArrAdd(ia, newIntv(is, ie));
  }
#+end_src
#+begin_src latex
  If a unique window is found outside a unique
  interval, a new unique interval is created.
#+end_src
#+begin_src C <<Outside unique interval>>=
  if (c >= mc) {
    in = 1;
    is = m - args->w / 2;
    ie = m + args->w / 2 - 1;
  }
#+end_src
#+begin_src latex
  The array of unique intervals is now converted to the corresponding
  array of sequences. The templates are numbered and their lengths are
  included in the headers. Once the templates have been written, the
  interval array is freed.
#+end_src
#+begin_src C <<Prepare array of unique sequences>>=
  SeqArr *sa = newSeqArr();
  char name[1024];
  for (int i = 0; i < ia->n; i++) {
    Intv *iv = ia->arr[i];
    sprintf(name, "template_%d %d\n", i + 1, iv->e - iv->s + 1);
    Seq *s = newSeq(name);
    //<<Copy sequence data>>
    seqArrAdd(sa, s);
  }
  freeIntvArr(ia);
  if (args->u) {
    for (int i = 0; i < sa->n; i++)
      printSeq(stdout, sa->arr[i], -1);
    exit(0);
  }
#+end_src
#+begin_src latex
  To copy the sequence data, memory is allocated, each nucleotide
  copied, and the sequence string terminated by the null character.
#+end_src
#+begin_src C <<Copy sequence data>>=
  s->data = emalloc(iv->e - iv->s + 2);
  for (int j = iv->s; j <= iv->e; j++)
    s->data[s->l++] = rs->data[j];
  s->data[s->l] = '\0';
#+end_src
#+begin_src latex
  \subsubsection{Check Unique Templates}
  The intervals in hand are candidates for template sequences. But
  before they are printed, they are checked for presence in all targets
  and absence from all neighbors using BLAST. Presence in all targets is
  done first and templates not found in every target are deleted.
#+end_src
#+begin_src C <<Check presence in all targets>>=
  //<<Search targets>>
  //<<Delete non-ubiquitous templates>>
#+end_src
#+begin_src latex
  Before searching among the targets, they are counted. The search pipe
  is constructed using this count, and the templates are written to it.
#+end_src
#+begin_src C <<Search targets>>=
  int nt = 0;
  //<<Count target sequences>>
  //<<Construct target pipe>>
  //<<Write templates to target pipe>>
#+end_src
#+begin_src latex
  The targets are counted by parsing the sequences in the BLAST
  database.
#+end_src
#+begin_src C <<Count target sequences>>=
  tmpl = "blastdbcmd -entry all -db %s/blastdb | "
    "grep -c '^>t'";
  sprintf(cmd, tmpl, args->d);
  pp = epopen(cmd, "r");
  if (fscanf(pp, "%d", &nt) == EOF)
    error("couldn't run %s\n", cmd);
  pclose(pp);
#+end_src
#+begin_src latex
  The command of the target pipe begins with a BLAST search among the
  targets. This is filtered by an AWK script to count the number of
  exact matches per template. The names of templates that match every
  target are written to file. Since \emph{exact} matches are required,
  the BLAST search is customized, such that it contains the query length
  in its output. Only hits where the query length is equal to the
  alignment length without mismatches are counted. Also, multiple hits
  to the same subject are counted only once. To facilitate the
  identification of templates, their names are reduced to their indexes
  in the template array. So \texttt{template\_x} becomes
  \texttt{x}. The indexes are sorted and written to a file located in
  the directory that also houses the \texttt{fur} database.
#+end_src
#+begin_src C <<Construct target pipe>>=
  tmpl = "blastn -db %s/blastdb -num_threads %d -outfmt "
    "\"6 sacc qacc qlen length mismatch\" | "
    "grep '^t' | "
    "awk -v n=%d '$3==$4 && $5==0 "
    "{i = $1 $2; if (!u[i]) {u[i]++; c[$2]++}} "
    "END {for (a in c) if (c[a] == n) print a}' | "
    "sed 's/template_//' | awk '{print --$1}' | "
    "sort -n > %s";
  char *of = estrdup(args->d);
  of = erealloc(of, strlen(of) + 5);
  strcat(of, "/out");
  sprintf(cmd, tmpl, args->d, args->t, nt, of);
#+end_src
#+begin_src latex
  The functions \texttt{strlen} and \texttt{strcat} are declared in
  \texttt{string.h}.
#+end_src
#+begin_src C <<Include headers>>=
  #include <string.h>
#+end_src
#+begin_src latex
  At the end of the program, the output file is removed and its name
  freed.
#+end_src
#+begin_src C <<Free memory>>=
  sprintf(cmd, "rm %s", of);
  if (system(cmd) < 0)
    error("couldn't run system call %s\n", cmd);
  free(of);
#+end_src
#+begin_src latex
  The templates are written to the target pipe.
#+end_src
#+begin_src C <<Write templates to target pipe>>=
  fprintf(stderr, "# Searching targets...");
  pp = epopen(cmd, "w");
  for (int i = 0; i < sa->n; i++)
    printSeq(pp, sa->arr[i], -1);
  pclose(pp);
  fprintf(stderr, "done.\n");
#+end_src
#+begin_src latex
  The output of the search consists of the templates \emph{not} to be
  deleted. Since they are in numerical order, deleting all other
  templates is achieved in two succinct steps. First parse the output
  file and delete everything but the sequences listed there, then delete
  the remaining sequences.
#+end_src
#+begin_src C <<Delete non-ubiquitous templates>>=
  FILE *fp = efopen(of, "r");
  int index, ii = 0;
  //<<Scan output file>>
  //<<Remove remaining sequences>>
  fclose(fp);
#+end_src
#+begin_src latex
  Say, there are 10 template candidates, $\{1,2,...,10\}$, and the
  output file has entries 5 and 7. Scanning it leads to the removal of
  templates 1--4 and 6. Removal consists of freeing the memory and
  setting the variable to NULL. The names of the remaining templates are
  printed to standard error.
#+end_src
#+begin_src C <<Scan output file>>=
  while (fscanf(fp, "%d", &index) != EOF) {
    for ( ; ii < index; ii++) {
      freeSeq(sa->arr[ii]);
      sa->arr[ii] = NULL;
    }
    fprintf(stderr, "# Found in all targets: %s\n",
	    sa->arr[ii++]->name);
  }
#+end_src
#+begin_src latex
  Recall that our example file has entries 5 and 7. After it has been
  scanned, templates 8--10 still need to be removed.
#+end_src
#+begin_src C <<Remove remaining sequences>>=
  for ( ; ii < sa->n; ii++) {
    freeSeq(sa->arr[ii]);
    sa->arr[ii] = NULL;
  }
#+end_src
#+begin_src latex
  The absence of the remaining templates among the neighbors is
  established in a similar way. The candidate templates are searched in
  the BLAST database and the hits written to file. This file is read
  back into the program, only this time it contains the templates to be
  deleted rather than the ones to be kept.
#+end_src
#+begin_src C <<Check absence from all neighbors>>=
  //<<Search neighbors>>
  //<<Delete templates found among neighbors>>
#+end_src
#+begin_src latex
  The neighborhood database is searched by constructing the
  \texttt{blastn} pipe and then sending the neighbors down that pipe.
#+end_src
#+begin_src C <<Search neighbors>>=
  //<<Construct neighbor pipe>>
  //<<Write templates to neighbor pipe>>
#+end_src
#+begin_src latex
  The command of the neighbor pipe has three parts: Run BLAST, count the
  number of hits among the neighbors, and write the indexes of the
  templates with at least one hit to file.
#+end_src
#+begin_src C <<Construct neighbor pipe>>=
  tmpl = "blastn -db %s/blastdb -num_threads %d "
    "-outfmt \"6 sacc qacc\" | "
    "grep '^n' | "
    "awk '{n[$2]++} "
    "END {for (a in n) if (n[a]) print a}' > %s";
  sprintf(cmd, tmpl, args->d, args->t, of);
  pp = epopen(cmd, "w");
#+end_src
#+begin_src latex
  Now the template candidates previously found in all targets are
  written to pipe with their index numbers as FASTA identifiers.
#+end_src
#+begin_src C <<Write templates to neighbor pipe>>=
  fprintf(stderr, "# Searching neighbors...");
  for (int i = 0; i < sa->n; i++)
    if (sa->arr[i])
      fprintf(pp, ">%d\n%s\n", i, sa->arr[i]->data);
  pclose(pp);
  fprintf(stderr, "done.\n");
#+end_src
#+begin_src latex
  The BLAST result is read and the template candidates found among the
  neighbors are deleted.
#+end_src
#+begin_src C <<Delete templates found among neighbors>>=
  fp = efopen(of, "r");
  while (fscanf(fp, "%d", &ii) != EOF) {
    fprintf(stderr, "# Found among neighbors: %s\n", sa->arr[ii]->name);
    freeSeq(sa->arr[ii]);
    sa->arr[ii] = NULL;
  }
  fclose(fp);
#+end_src
#+begin_src latex
  The last step in \texttt{fur} is to print the template sequences that
  passed both the presence and the absence test.
#+end_src
#+begin_src C <<Print templates>>=
  for (int i = 0; i < sa->n; i++)
    if (sa->arr[i])
      printSeq(stdout, sa->arr[i], -1);
  freeSeqArr(sa);
#+end_src
#+begin_src latex
  The program is now ready to be used.
  \section{Tutorial}\label{sec:tut}
  To demonstrate the application of \texttt{fur}, the example data shown
  in Figure~\ref{fig:eco} is analyzed with the aim of finding regions
  specific to the pathogenic \emph{E. coli} strain ST131.  The first
  step is to get the data. This is converted into a \texttt{fur}
  database and analyzed in an initial pass before the investigation is
  refined by varying the parameters of \texttt{fur}.
#+end_src
#+begin_src sh <<tutorial.sh>>=
  <<Get tutorial data>>
  <<Make fur database>>
  <<Analyze tutorial data>>
  <<Refine tutorial analysis>>
#+end_src
#+begin_src latex
  The example data is copied from a networked computer and unpacked.
#+end_src
#+begin_src sh <<Get tutorial data>>=
  wget guanine.evolbio.mpg.de/fur/eco105.tar.gz
  tar -xvzf eco105.tar.gz
#+end_src
#+begin_src latex
  This generates two directories of genomes in FASTA format,
  \texttt{targets} with 98 genomes, and \texttt{neighbors} with
  seven. These are converted to a \texttt{fur} database using
  \texttt{makeFurDb}\footnote{\texttt{https://github.com/haubold/makeFurDb}},
  which takes approximately 35 s.
#+end_src
#+begin_src sh <<Make fur database>>=
  makeFurDb -t targets -n neighbors -d furDb
#+end_src
#+begin_src latex
  Unique templates are found by applying \texttt{fur} to this database,
  which takes only 5.4 s. The template sequences are stored in
  \texttt{tmpl.fasta}.
#+end_src
#+begin_src sh <<Analyze tutorial data>>=
  fur -d furDb > tmpl.fasta
#+end_src
#+begin_src latex
  The program lists thirteen regions present in all targets, followed by
  four found among the neighbors. So there are $13-4=9$ templates in
  \texttt{tmpl.fasta}. Use AWK to find that their combined length is 5.8
  kb.
#+end_src
#+begin_src sh <<Analyze tutorial data>>=
  awk '/^>/{c++; s += $2} END {printf "%d tmpl, %d bp\n", c, s}' \
      tmpl.fasta
#+end_src
#+begin_src latex
  The first parameter to explore is window length, \texttt{-w}. Longer
  windows result in fewer candidate regions. For example, with 1 kb
  windows, one template is found in all targets, but it is also found
  among the neighbors, so no template is returned.
#+end_src
#+begin_src sh <<Refine tutorial analysis>>=
  fur -d furDb -w 1000 
#+end_src
#+begin_src latex
  On the other hand, reducing the window length to 250 bp yields 36
  templates with 13.9 kb. Clearly, \texttt{fur} is highly sensitive to
  the window length and this should be borne in mind when investigating
  other pathogens.
#+end_src
#+begin_src sh <<Refine tutorial analysis>>=
  fur -d furDb -w 250 |
      awk '/^>/{c++; s += $2} END {printf "%d tmpl, %d bp\n", c, s}'
#+end_src
#+begin_src latex
  The second parameter to explore is the CDF-value, or $P$-value
  corresponding to the complexity threshold used by the program,
  \texttt{-p} (Figure~\ref{fig:cdf}). By default this is
  0.95. Increasing it to 1 abolishes all templates, but setting it just
  below 1 to $P=0.99999$ increases the yield to 20 templates with 13.3
  kb. So it might well be worth testing different $P$-values and window
  lengths in other analyses. This can be done conveniently because each
  run of \texttt{fur} takes only a few seconds once the underlying
  database has been computed.
#+end_src
#+begin_src sh <<Refine tutorial analysis>>=
  fur -d furDb -p 0.99999 |
      awk '/^>/{c++; s += $2} END {printf "%s tmpl, %d bp\n", c, s}'
#+end_src
#+begin_src latex
  \section{List of code chunks}
  \nowebchunks
#+end_src
