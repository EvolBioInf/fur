#+begin_src latex
  \section{Introduction}
  The design of diagnostic PCR primers is often hampered by an excess of
  candidates that also amplify off-target regions. To minimize the
  chance of cross-amplification, primers should be designed from
  template sequences that are unique to the target strain. The program
  \texttt{fur} \emph{finds unique regions} by comparing the genomes of a
  sample of target strains to the genomes of the closest relatives the
  targets are to be distinguished from. The underlying heuristic is that
  any region that distinguishes a target from its closest relatives,
  also distinguishes it from all other sequences out there.

  Consider, for example, \textit{Escherichia coli} ST131, a multi-drug
  resistant strain that causes urinary tract and blood infections in
  humans~\cite{pet14:glo}. \emph{E. coli} ST131 belongs to the B2
  phylogenetic subgroup, which corresponds to serotype O25b:H4.
  Figure~\ref{fig:eco} shows the phylogeny of 105 \emph{E. coli} B2
  strains. The clade marked ST131 comprises 95 strains newly sequenced
  by~\cite{pet14:glo}, plus three STS131 reference genomes, SE15, NA114,
  and EC958. This clade defines the \emph{targets} marked $\mathcal{T}$
  in Figure~\ref{fig:eco}. The seven remaining
  \emph{E. coli} strains are the \emph{neighbors}, $\mathcal{N}$. They also
  belong to the B2 group, but not to ST131~\cite{pet14:glo}. The aim is
  to find regions specific to ST131. In Section~\ref{sec:tut} a
  tutorial-style analysis of this data set shows how to do this
  using \texttt{fur}.

      \begin{figure}
	\begin{center}
	  \tiny
	  \resizebox{\textwidth}{!}{\input{eco105}}
	\end{center}
	\caption{Phylogeny of 105 strains of \emph{Eschericia coli}
	  computed from whole genome sequences using
	  \texttt{andi}~\cite{hau15:and}. The scale bar is the number of
	  substitutions per site. The clade marked ST131 contains the
	  pathogenic targets ($\mathcal{T}$), the remaining seven
	  strains are the neighbors ($\mathcal{N}$).}\label{fig:eco}
      \end{figure}

  The program takes as input a database computed using
  \texttt{makeFurDb}\footnote{\texttt{https://github.com/haubold/makeFurDb/}}
  from two directories of sequence files, the first contains one or more
  target genomes, the second one or more neighbor genomes. \texttt{fur}
  uses \texttt{macle}~\cite{pir18:hig} to identify candidate regions
  that are unique to a representative target when compared to all
  neighbors. These candidate regions are then checked for presence in
  all targets and absence from all neighbors using BLAST. The resulting
  templates are finally printed to screen. They are now ready for
  submission to a primer design program like
  Primer-BLAST~\cite{ye12:pri}.

  \section{Implementation}
  The program is based on arrays of sequences and arrays of intervals on
  those sequences. Arrays of sequences are defined in \texttt{seq.h},
  while intervals and their arrays are still to be defined. Apart from
  data structures for intervals and their arrays, the program consists
  of the usual include section, declarations and definitions of
  functions, and finally the \texttt{main} function.
#+end_src
#+begin_src C <<fur.c>>=
  #include "seq.h"
  //<<Include headers>>
  //<<Data structures>>
  //<<Function declarations>>
  //<<Function definitions>>
  //<<Main function>>
#+end_src
#+begin_src latex
  \subsection{Arrays of Intervals}
  Intervals and their arrays are the basic hitherto undefined building
  blocks of \texttt{fur}, so they are defined first. Intervals have a
  start and an end.
#+end_src
#+begin_src C <<Data structures>>=
  typedef struct intv {
    int s, e;
  } Intv;
#+end_src
#+begin_src latex
  An arbitrary number of $n$ intervals is stored in an \emph{interval array}.
#+end_src
#+begin_src C <<Data structures>>=
  typedef struct intvArr {
    Intv **arr;
    int n;
  } IntvArr;
#+end_src
#+begin_src latex
  Interval arrays require functions for construction, freeing, and
  addition. Construction is declared with start and end positions
  supplied as parameters.
#+end_src
#+begin_src C <<Function declarations>>=
  Intv *newIntv(int s, int e);
#+end_src
#+begin_src latex
  These positions are saved once space has been made for them.
#+end_src
#+begin_src C <<Function definitions>>=
  Intv *newIntv(int s, int e) {
    Intv *i = (Intv *)emalloc(sizeof(Intv));
    i->s = s;
    i->e = e;
    return i;
  }
#+end_src
#+begin_src latex
  The function \texttt{emalloc} is declared in \texttt{error.h}.
#+end_src
#+begin_src C <<Include headers>>=
  #include "error.h"
#+end_src
#+begin_src latex
  Next, the construction of an interval array is declared.
#+end_src
#+begin_src C <<Function declarations>>=
  IntvArr *newIntvArr();
#+end_src
#+begin_src latex
  Its definition returns an empty array of intervals.
#+end_src
#+begin_src C <<Function definitions>>=
  IntvArr *newIntvArr() {
    IntvArr *ia = (IntvArr *)emalloc(sizeof(IntvArr));
    ia->arr = NULL;
    ia->n = 0;
    return ia;
  }
#+end_src
#+begin_src latex
  And to deconstruct, the freeing of an interval array is declared.
#+end_src
#+begin_src C <<Function declarations>>=
  void freeIntvArr(IntvArr *ia);
#+end_src
#+begin_src latex
  Its definition frees each interval in turn before freeing the interval
  array itself.
#+end_src
#+begin_src C <<Function definitions>>=
  void freeIntvArr(IntvArr *ia) {
    for (int i = 0; i < ia->n; i++)
      free(ia->arr[i]);
    free(ia->arr);
    free(ia);
  }
#+end_src
#+begin_src latex
  Declare the addition of an interval to an existing interval array.
#+end_src
#+begin_src C <<Function declarations>>=
  void intvArrAdd(IntvArr *ia, Intv *i);
#+end_src
#+begin_src latex
  The definition makes space for the newly arrived interval and then
  adds it.
#+end_src
#+begin_src C <<Function definitions>>=
  void intvArrAdd(IntvArr *ia, Intv *i) {
    ia->arr = (Intv **)
      erealloc(ia->arr, (ia->n + 1) * sizeof(Intv *));
    ia->arr[ia->n++] = i;
  }
#+end_src
#+begin_src latex
  Interval arrays are now ready to be used. This is done in the
  \texttt{main} function, which first interacts with the user, then
  analyzes the targets and neighbors, and finally prints the desired
  templates. At the end of the program any memory still allocated is
  freed.
#+end_src
#+begin_src C <<Main function>>=
  int main(int argc, char **argv) {
    // <<Interact with user>>
    // <<Analyze sequences>>
    // <<Print templates>>
    // <<Free memory>>
  }
#+end_src
#+begin_src latex
  \subsection{User Interaction}
  Whenever the program interacts with the user, it identifies itself, so
  its name is set.
#+end_src
#+begin_src C <<Interact with user>>=
  setprogname(argv[0]);
#+end_src
#+begin_src latex
  The function \texttt{setprogname} is declared in the standard part of
  the BSD library.
#+end_src
#+begin_src C <<Include headers>>=
  #include <bsd/stdlib.h>
#+end_src
#+begin_src latex
  The user interaction is mediated via a container holding the options
  and their arguments.
#+end_src
#+begin_src C <<Interact with user>>=
  Args *args = getArgs(argc, argv);
#+end_src
#+begin_src latex
  The \texttt{Args} data structure and the \texttt{getArgs} function are
  declared in \texttt{interface.h}.
#+end_src
#+begin_src C <<Include headers>>=
  #include "interface.h"
#+end_src
#+begin_src latex
  The argument container is freed at the end.
#+end_src
#+begin_src C <<Free memory>>=
  freeArgs(args);
#+end_src
#+begin_src latex
  The options passed via \texttt{args} might include a request for help,
  or indicate an error. In that case, \texttt{printUsage}, which is also
  declared in \texttt{interface.h}, emits a usage message before
  exiting.
#+end_src
#+begin_src C <<Interact with user>>=
  if (args->h || args->err)
    printUsage();
#+end_src
#+begin_src latex
  Alternatively, the user might request information about the program,
  whereupon it makes a modest splash and exits.
#+end_src
#+begin_src C <<Interact with user>>=
  if (args->v)
    printSplash(args);
#+end_src
#+begin_src latex
  \subsection{Find Unique Templates}
  Analysis of the targets and neighbors proceeds in two steps. Unique
  regions are first identified by comparing one representative target to
  all neighbors. Then the unique regions are checked for presence in all
  targets and absence from all neighbors.
#+end_src
#+begin_src C <<Analyze sequences>>=
  //<<Identify unique regions>>
  //<<Check presence in all targets>>
  //<<Check absence from all neighbors>>
#+end_src
#+begin_src latex
  Unique regions are identified using the external program
  \texttt{macle}\footnote{\texttt{https://github.com/evolbioinf/macle}}~\cite{pir18:hig}. This
  operates by traversing a pre-computed index. The index is part of the
  \texttt{fur} database and contains the neighbors augmented by the
  representative target. This index is used to compute local complexity
  values for identifying unique intervals.
#+end_src
#+begin_src C <<Identify unique regions>>=
  //<<Get representative target>>
  //<<Construct unique intervals>>
#+end_src
#+begin_src latex
  To obtain the representative target, its name is needed, which allows
  retrieval of its sequence.
#+end_src
#+begin_src C <<Get representative target>>=
  char rn[256];
  Seq *rs = NULL;
  //<<Get representative name>>
  //<<Get representative sequence>>
#+end_src
#+begin_src latex
  The representative name is obtained from the \texttt{macle} index,
  where it is first in the name list. This ordering is ensured by the
  program \texttt{makeFurDb}.
#+end_src
#+begin_src C <<Get representative name>>=
  char *tmpl = "macle -l %s/macle.idx | "
    "head -n 6 | tail -n 1 | "
    "awk '{print $6 }'";
  char cmd[1024];
  sprintf(cmd, tmpl, args->d);
  FILE *pp = epopen(cmd, "r");
  if (fscanf(pp, "%s", rn) == EOF)
    error("couldn't run %s\n", cmd);
  pclose(pp);
#+end_src
#+begin_src latex
  With the sequence name as handle, the corresponding sequence is
  extracted from the BLAST database.
#+end_src
#+begin_src C <<Get representative sequence>>=
  tmpl = "blastdbcmd -entry %s -db %s/blastdb";
  sprintf(cmd, tmpl, rn, args->d);
  pp = epopen(cmd, "r");
  Seq *sp;
  while ((sp = getSeq(pp)) != NULL)
    rs = sp;
  pclose(pp);
#+end_src
#+begin_src latex
  The representative target is freed at the end of the program.
#+end_src
#+begin_src C <<Free memory>>=
  freeSeq(rs);
#+end_src
#+begin_src latex
  To construct unique intervals, the complexity threshold indicating
  uniqueness is computed as preparation for the sliding window analysis
  of local complexity. Figure~\ref{fig:sw} shows a cartoon of a sliding
  window analysis. The overlapping windows returned by \texttt{macle}
  are characterized by their mid-points (dots) and are either unique
  (lightgray) or not (black). Unique windows are summarized into unique
  intervals (dashed). The user is told about the size of the preliminary
  template set, and the array of unique intervals is eventually
  converted into an array of unique sequences, the template candidates.

  \begin{figure}
    \begin{center}
      \input{sw}
    \end{center}
    \caption{Sliding window analysis of a genome sequence. The
      overlapping windows are centered on their mid-points (dots) and
      their complexity is either greater than the threshold, which makes
      them unique (lightgray), or not (black). Unique windows are
      summarized into the unique intervals $I_1$ and $I_2$ (dashed).}\label{fig:sw}
  \end{figure}

#+end_src
#+begin_src C <<Construct unique intervals>>=
  double mc, gc = 0.;
  long len = 0;
  IntvArr *ia;
  //<<Compute complexity threshold>>
  //<<Sliding window analysis>>
  //<<Report result of sliding window analysis>>
  //<<Prepare array of unique sequences>>
#+end_src
#+begin_src latex
  The complexity threshold is a function of aggregate sequence length,
  GC-content, window length, and the inverse of the cumulative
  distribution function (CDF) of the match length null
  distribution. Figure~\ref{fig:cdf} shows this function and how
  choosing a particular CDF-value, on the $y$-axis, 0.95 in the example,
  corresponds to a complexity-threshold on the $x$-axis, 0.019. Sequence
  length and GC content are looked up in the \texttt{macle} index,
  window length and probability supplied by the user.

  \begin{figure}
    \begin{center}
      \scalebox{0.6}{\input{cdf}}
    \end{center}
    \caption{Cumulative distribution function (CDF) of the match
      complexity ($C_{\rm m}$) in 500 bp windows over a 35.5 Mb data set
      with GC-content 0.5~\cite{pir18:hig}. The parameter choice
      corresponds to the neighbors depicted in Figure~\ref{fig:eco}. The
      vertical line indicates the complexity threshold for a cumulative
      value of 0.95.}\label{fig:cdf}
  \end{figure}
#+end_src
#+begin_src C <<Compute complexity threshold>>=
  tmpl = "macle -l %s/macle.idx | "
    "tail -n +2 | "
    "awk '{print $2}'";
  sprintf(cmd, tmpl, args->d);
  pp = epopen(cmd, "r");
  if (fscanf(pp, "%ld", &len) == EOF)
    error("couldn't run %s\n", cmd);
  if (fscanf(pp, "%lf", &gc) == EOF)
    error("couldn't run %s\n", cmd);
  mc = quantCm(len, gc, args->w, args->p);
  pclose(pp);
#+end_src
#+begin_src latex
  The function \texttt{quantCm} is part of the
  \texttt{matchLen}\footnote{\texttt{https://github.com/evolbioinf/matchLen}}
  library.
#+end_src
#+begin_src C <<Include headers>>=
  #include "matchLen.h"
#+end_src
#+begin_src latex
  A sliding window analysis by \texttt{macle} returns pairs of values,
  $(m, C_{\rm m})$, where $m$ is the window midpoint and $C_{\rm m}$ its
  complexity. Let $t$ be the uniqueness threshold. If $C_{\rm m}\ge t$,
  the corresponding window is deemed unique. It also belongs to a unique
  interval of one or more overlapping unique windows. As the algorithm
  parses the windows from left to right, it toggles between being inside
  or outside a unique interval.
#+end_src
#+begin_src C <<Sliding window analysis>>=
  //<<Prepare sliding window analysis>>
  while (fscanf(pp, "%f %f", &m, &c) != EOF) {
    //<<Determine window start and end>>
    if (in) {
      //<<Inside unique interval>>
    } else {
      //<<Outside unique interval>>
    }
  }
  pclose(pp);
#+end_src
#+begin_src latex
  The sliding window analysis requires the opening of a pipe for reading
  \texttt{macle} output. The pipe command consists of three steps. The
  first calls \texttt{macle}, the second cuts the $(m,C_{\rm m})$ pairs
  from the output, and the third removes windows without reliable
  sequence data, where $C_{\rm m}=-1$. In addition, the sliding window
  analysis requires variables for holding the current midpoint and
  complexity values, the interval array, and a variable to indicate
  whether the program is inside a unique interval or not.
#+end_src
#+begin_src C <<Prepare sliding window analysis>>=
  tmpl =
    "macle -i %s/macle.idx -n %s -w %d -k %d | "
    "cut -f 2,3 | "
    "awk '$2 > -1'";
  sprintf(cmd, tmpl, args->d, rn, args->w, args->k);
  pp = epopen(cmd, "r");
  float m, c;
  ia = newIntvArr();
  int is, ie, in = 0;
#+end_src
#+begin_src latex
  The start and end points of a window are calculated roughly as $m\pm w
  / 2$, where $w$ is the window length. To get the borders exactly
  right, consider a sequence of length 100, for which \texttt{macle}
  prints a mid-point of 50. To recover the correct start and end
  positions of 1 and 100 from this, compute
  \begin{eqnarray*}
    \mbox{start} & = & m - w / 2 + 1\\
    \mbox{end}   & = & m + w / 2
  \end{eqnarray*}                 
  Since positions in strings are zero-based, while \texttt{macle} output
  is one-based, the final start and end values are shifted by one
  position to the left.
#+end_src
#+begin_src C <<Determine window start and end>>=
  int ws = m - args->w / 2;
  int we = m + args->w / 2 - 1;
#+end_src
#+begin_src latex
  If a unique \emph{window} overlaps an existing unique \emph{interval},
  the interval is extended to the right (Figure~\ref{fig:sw}). If the
  unique window lies beyond the existing interval, the interval is
  ``closed'' at the endpoint found in the last extension and added to
  the interval array. Note that the interval is \emph{not} closed as
  soon as it cannot be extended. Such a rule would break up $I_1$ in
  Figure~\ref{fig:sw} into two overlapping and hence redundant
  intervals.
#+end_src
#+begin_src C <<Inside unique interval>>=
  if (ws <= ie && c >= mc)
    ie = we;
  else if (ws > ie) {
    in = 0;
    intvArrAdd(ia, newIntv(is, ie));
  }
#+end_src
#+begin_src latex
  If a unique window is found outside a unique
  interval, a new unique interval is created.
#+end_src
#+begin_src C <<Outside unique interval>>=
  if (c >= mc) {
    in = 1;
    is = m - args->w / 2;
    ie = m + args->w / 2 - 1;
  }
#+end_src
#+begin_src latex
  The result of the sliding window analysis is reported.
#+end_src
#+begin_src C <<Report result of sliding window analysis>>=
  long nn = 0;
  for (int i = 0; i < ia->n; i++)
    nn += ia->arr[i]->e - ia->arr[i]->s + 1;
  char *h1 = "# Step                    Sequences  Nucleotides";
  char *h2 = "# ----------------------------------------------";
  fprintf(stderr, "%s\n%s\n", h1, h2);
  tmpl = "# Sliding window             %6d     %8ld\n";
  fprintf(stderr, tmpl, ia->n, nn);
#+end_src
#+begin_src latex
  The array of unique intervals is now converted to the corresponding
  array of sequences. The templates are numbered and their lengths are
  included in the headers. Once the templates have been written, the
  interval array is freed. For debugging purposes, the program can also
  print the unique sequences.
#+end_src
#+begin_src C <<Prepare array of unique sequences>>=
  SeqArr *sa = newSeqArr();
  char name[1024];
  for (int i = 0; i < ia->n; i++) {
    Intv *iv = ia->arr[i];
    sprintf(name, "template_%d %d\n", i + 1, iv->e - iv->s + 1);
    Seq *s = newSeq(name);
    //<<Copy sequence data>>
    seqArrAdd(sa, s);
  }
  freeIntvArr(ia);
  //<<Print unique sequences?>>
#+end_src
#+begin_src latex
  After printing the unique sequences, the program exits.
#+end_src
#+begin_src C <<Print unique sequences?>>=
  if (args->u) {
    for (int i = 0; i < sa->n; i++)
      printSeq(stdout, sa->arr[i], -1);
    exit(0);
  }
#+end_src
#+begin_src latex
  To copy the sequence data, memory is allocated, each nucleotide
  copied, and the sequence string terminated by the null character.
#+end_src
#+begin_src C <<Copy sequence data>>=
  s->data = emalloc(iv->e - iv->s + 2);
  for (int j = iv->s; j <= iv->e; j++)
    s->data[s->l++] = rs->data[j];
  s->data[s->l] = '\0';
#+end_src
#+begin_src latex
  \subsection{Check Unique Templates}
  The intervals in hand are candidates for template sequences. But
  before they are printed, they are checked for presence in all targets
  and absence from all neighbors using BLAST. Presence in all targets is
  done first and templates not found in every target are deleted. The
  current size of the result set is reported.
#+end_src
#+begin_src C <<Check presence in all targets>>=
  //<<Search targets>>
  //<<Delete non-ubiquitous templates>>
  //<<Report result of presence test>>
#+end_src
#+begin_src latex
  Before searching among the targets, they are counted. The search pipe
  is constructed using this count, and the templates are written to it.
#+end_src
#+begin_src C <<Search targets>>=
  int nt = 0;
  //<<Count target sequences>>
  //<<Construct target pipe>>
  //<<Write templates to target pipe>>
#+end_src
#+begin_src latex
  The targets are counted by parsing the sequences in the BLAST
  database.
#+end_src
#+begin_src C <<Count target sequences>>=
  tmpl = "blastdbcmd -entry all -db %s/blastdb | "
    "grep -c '^>t'";
  sprintf(cmd, tmpl, args->d);
  pp = epopen(cmd, "r");
  if (fscanf(pp, "%d", &nt) == EOF)
    error("couldn't run %s\n", cmd);
  pclose(pp);
#+end_src
#+begin_src latex
  The command of the target pipe begins with a BLAST search among the
  targets. This is filtered by an AWK script to count the number of
  matches per template. The names of templates that match every target
  are written to file. Since \emph{exact} matches are required by
  default, the BLAST search is customized, such that it contains the
  query length in its output. Only hits where the query length is equal
  to the alignment length without mismatches are counted. However, the
  user can change this default behavior by setting a minimum length of
  the alignment and/or a minimum percent identity. In addition, multiple
  hits to the same subject are counted only once. To facilitate the
  identification of templates, their names are reduced to their indexes
  in the template array. So \texttt{template\_x} becomes \texttt{x}. The
  indexes are sorted and written to a file located in the directory that
  also houses the \texttt{fur} database.
#+end_src
#+begin_src C <<Construct target pipe>>=
  tmpl = "blastn -db %s/blastdb -num_threads %d -outfmt "
    "\"6 sacc qacc qlen length pident\" | "
    "grep '^t' | "
    "awk -v n=%d -v l=%d '((!l && $3==$4) || (l && $4>=l)) && $5>=%.3f "
    "{i = $1 $2; if (!u[i]) {u[i]++; c[$2]++}} "
    "END {for (a in c) if (c[a] == n) print a}' | "
    "sed 's/template_//' | awk '{print --$1}' | "
    "sort -n > %s";
  char *of = estrdup(args->d);
  of = erealloc(of, strlen(of) + 5);
  strcat(of, "/out");
  sprintf(cmd, tmpl, args->d, args->t, nt, args->l, args->i, of);
#+end_src
#+begin_src latex
  The functions \texttt{strlen} and \texttt{strcat} are declared in
  \texttt{string.h}.
#+end_src
#+begin_src C <<Include headers>>=
  #include <string.h>
#+end_src
#+begin_src latex
  At the end of the program, the output file is removed and its name
  freed.
#+end_src
#+begin_src C <<Free memory>>=
  sprintf(cmd, "rm %s", of);
  if (system(cmd) < 0)
    error("couldn't run system call %s\n", cmd);
  free(of);
#+end_src
#+begin_src latex
  The templates are written to the target pipe.
#+end_src
#+begin_src C <<Write templates to target pipe>>=
  pp = epopen(cmd, "w");
  for (int i = 0; i < sa->n; i++)
    printSeq(pp, sa->arr[i], -1);
  pclose(pp);
#+end_src
#+begin_src latex
  The output of the search consists of the templates \emph{not} to be
  deleted. Since they are in numerical order, deleting all other
  templates is achieved in two succinct steps. First, parse the output
  file and delete everything but the sequences listed there, then delete
  the remaining sequences.
#+end_src
#+begin_src C <<Delete non-ubiquitous templates>>=
  FILE *fp = efopen(of, "r");
  int index, ii = 0;
  //<<Scan output file>>
  //<<Remove remaining sequences>>
  fclose(fp);
#+end_src
#+begin_src latex
  Say, there are 10 template candidates, $\{1,2,...,10\}$, and the
  output file has entries 5 and 7. Scanning it leads to the removal of
  templates 1--4 and 6. Removal consists of freeing the memory and
  setting the variable to NULL. The names of the remaining templates are
  printed to standard error.
#+end_src
#+begin_src C <<Scan output file>>=
  while (fscanf(fp, "%d", &index) != EOF) {
    for ( ; ii < index; ii++) {
      freeSeq(sa->arr[ii]);
      sa->arr[ii] = NULL;
    }
    ii++;
  }
#+end_src
#+begin_src latex
  Recall that our example file has entries 5 and 7. After it has been
  scanned, templates 8--10 still need to be removed.
#+end_src
#+begin_src C <<Remove remaining sequences>>=
  for ( ; ii < sa->n; ii++) {
    freeSeq(sa->arr[ii]);
    sa->arr[ii] = NULL;
  }
#+end_src
#+begin_src latex
  The user is told about the result of the presence test.
#+end_src
#+begin_src C <<Report result of presence test>>=
  nn = 0;
  int ns = 0;
  for (int i = 0; i < sa->n; i++)
    if (sa->arr[i]) {
      nn += sa->arr[i]->l;
      ns++;
    }
  tmpl = "# Presence in targets        %6d     %8ld\n";
  fprintf(stderr, tmpl, ns, nn);
#+end_src
#+begin_src latex
  The absence of the remaining templates among the neighbors is
  established in a similar way. The candidate templates are searched in
  the BLAST database and the hits written to file. This file is read
  back into the program, only this time it contains the templates to be
  deleted rather than the ones to be kept. At the end, the result of
  this absence test is reported.
#+end_src
#+begin_src C <<Check absence from all neighbors>>=
  //<<Search neighbors>>
  //<<Delete templates found among neighbors>>
  //<<Report result of absence test>>
#+end_src
#+begin_src latex
  The neighborhood database is searched by constructing the
  \texttt{blastn} pipe and then sending the neighbors down that pipe.
#+end_src
#+begin_src C <<Search neighbors>>=
  //<<Construct neighbor pipe>>
  //<<Write templates to neighbor pipe>>
#+end_src
#+begin_src latex
  The command of the neighbor pipe has three parts: Run BLAST, count the
  number of hits among the neighbors, and write the indexes of the
  templates with at least one hit to file.
#+end_src
#+begin_src C <<Construct neighbor pipe>>=
  tmpl = "blastn -db %s/blastdb -num_threads %d "
    "-outfmt \"6 sacc qacc\" | "
    "grep '^n' | "
    "awk '{n[$2]++} "
    "END {for (a in n) if (n[a]) print a}' > %s";
  sprintf(cmd, tmpl, args->d, args->t, of);
  pp = epopen(cmd, "w");
#+end_src
#+begin_src latex
  Now the template candidates previously found in all targets are
  written to pipe with their index numbers as FASTA identifiers.
#+end_src
#+begin_src C <<Write templates to neighbor pipe>>=
  for (int i = 0; i < sa->n; i++)
    if (sa->arr[i])
      fprintf(pp, ">%d\n%s\n", i, sa->arr[i]->data);
  pclose(pp);
#+end_src
#+begin_src latex
  The BLAST result is read and the template candidates found among the
  neighbors are deleted.
#+end_src
#+begin_src C <<Delete templates found among neighbors>>=
  fp = efopen(of, "r");
  while (fscanf(fp, "%d", &ii) != EOF) {
    freeSeq(sa->arr[ii]);
    sa->arr[ii] = NULL;
  }
  fclose(fp);
#+end_src
#+begin_src latex
  The result of the absence test is also the final result of the
  analysis.
#+end_src
#+begin_src C  <<Report result of absence test>>=
  nn = 0;
  ns = 0;
  for (int i = 0; i < sa->n; i++)
    if (sa->arr[i]) {
      nn += sa->arr[i]->l;
      ns++;
    }
  tmpl = "# Absence from neighbors     %6d     %8ld\n";
  fprintf(stderr, tmpl, ns, nn);
#+end_src
#+begin_src latex
  The last step in \texttt{fur} is to print the template sequences that
  passed both the presence and the absence test.
#+end_src
#+begin_src C <<Print templates>>=
  for (int i = 0; i < sa->n; i++)
    if (sa->arr[i])
      printSeq(stdout, sa->arr[i], -1);
  freeSeqArr(sa);
#+end_src
#+begin_src latex
  The program is now ready to be used.
  \section{Tutorial}\label{sec:tut}
  To demonstrate the application of \texttt{fur}, the example data shown
  in Figure~\ref{fig:eco} is analyzed to find regions specific to the
  pathogenic \emph{E. coli} strain ST131.  The first step is to get the
  data. This is converted into a \texttt{fur} database and analyzed in
  an initial pass before the investigation is refined by varying the
  parameters of \texttt{fur}.
#+end_src
#+begin_src sh <<tutorial.sh>>=
  <<Get tutorial data>>
  <<Make fur database>>
  <<Analyze tutorial data>>
  <<Refine tutorial analysis>>
#+end_src
#+begin_src latex
  The example data is copied from a networked computer and unpacked.
#+end_src
#+begin_src sh <<Get tutorial data>>=
  wget guanine.evolbio.mpg.de/fur/eco105.tar.gz
  tar -xvzf eco105.tar.gz
#+end_src
#+begin_src latex
  This generates two directories of genomes in FASTA format,
  \texttt{targets} with 98 genomes, and \texttt{neighbors} with
  seven. These are converted to a \texttt{fur} database using
  \texttt{makeFurDb}\footnote{\texttt{https://github.com/haubold/makeFurDb}},
  which takes approximately 35 s.
#+end_src
#+begin_src sh <<Make fur database>>=
  makeFurDb -t targets -n neighbors -d furDb
#+end_src
#+begin_src latex
  Unique templates are found by applying \texttt{fur} to this database,
  which takes only 4.4 s. The template sequences are stored in
  \texttt{tmpl.fasta}.
#+end_src
#+begin_src sh <<Analyze tutorial data>>=
  fur -d furDb > tmpl.fasta
  # Step                    Sequences  Nucleotides
  # ----------------------------------------------
  # Sliding window                185       638000
  # Presence in targets             6         5450
  # Absence from neighbors          3         2150
#+end_src
#+begin_src latex
  The hash-tagged progress information lists the three steps of the
  algorithm and the number of sequences and nucleotides contained in the
  template set after each one. So the initial sliding window analysis
  uncovers 185 sequences totaling 638 kb. After checking for presence in
  all target sequences, 6 sequences with 5.5 kb remain. The final step
  of checking for absence from the neighborhood leaves three sequences
  with 2.2 kb as the template set.

  To make the process of template selection more transparent, the
  \texttt{-u} option is used to print the unique regions found in the
  sliding window analysis and exits.
#+end_src
#+begin_src sh <<Refine tutorial analysis>>=
  fur -d furDb -u > unique.fasta
#+end_src
#+begin_src latex
  The file \texttt{unique.fasta} now contains 185 sequences with 638000
  nucleotides, which can be checked using a short AWK script.
#+end_src
#+begin_src sh <<Refine tutorial analysis>>=
  awk '/^>/{c++; s += $2} END {printf "# %s tmpl, %d bp\n", c, s}' \
      unique.fasta
  # 185 tmpl, 638000 bp
#+end_src
#+begin_src latex
  The first parameter of \texttt{fur} to explore is window length,
  \texttt{-w}. Longer windows result in sequences that are more
  difficult to find as exact matches among all targets. For example,
  with 1 kb windows, there are 111 candidate regions, of which only one
  is present in all targets. However, it is also found among the
  neighbor sequences, leaving no templates. This is in spite of the fact
  that the amount of nucleotides returned from the sliding window
  analysis, 635 kb, is hardly changed from the previous 638 kb.
#+end_src
#+begin_src sh <<Refine tutorial analysis>>=
  fur -d furDb -w 1000
  # Step                    Sequences  Nucleotides
  # ----------------------------------------------
  # Sliding window                111       634900
  # Presence in targets             1         1400
  # Absence from neighbors          0            0
#+end_src
#+begin_src latex
  On the other hand, reducing the window length to 250 bp yields 14
  templates with 6.6 kb. Clearly, \texttt{fur} is highly sensitive to
  the window length and this should be borne in mind when investigating
  other pathogens.
#+end_src
#+begin_src sh <<Refine tutorial analysis>>=
  fur -d furDb -w 250 > tmpl.fasta
  # Step                    Sequences  Nucleotides
  # ----------------------------------------------
  # Sliding window                288       665550
  # Presence in targets            18         9575
  # Absence from neighbors         14         6625
#+end_src
#+begin_src latex
  The second parameter of interest is the minimum percent identity a
  BLAST hits to the target sequences. By default this is 100, but if
  lowered to 99, the default 500 bp windows analysis yields template
  candidates five with 3.6 kb instead of the previous three templates
  with 2.2 kb.
#+end_src
#+begin_src sh <<Refine tutorial analysis>>=
fur -d furDb -i 99 | cchar
# Step                    Sequences  Nucleotides
# ----------------------------------------------
# Sliding window                185       638000
# Presence in targets             9         7500
# Absence from neighbors          5         3550
#+end_src
#+begin_src latex
  If the minimum length of a target hit is now also reduced from the
  query length to 250 bp, the number of template candidates grows to 23
  with 73.9 kb. These would still have to be inspected in a multiple
  sequence alignment to find their intersection before primer design can
  begin.
#+end_src
#+begin_src sh <<Refine tutirial aslysis>>=
  fur -d furDb -i 99 -l 250 
  # Step                    Sequences  Nucleotides
  # ----------------------------------------------
  # Sliding window                185       638000
  # Presence in targets            32       101450
  # Absence from neighbors         23        73900
#+end_src
#+begin_src latex
  The final parameter to explore is the CDF-value, or $P$-value
  corresponding to the complexity threshold used by the program,
  \texttt{-p} (Figure~\ref{fig:cdf}). By default this is
  0.95. Increasing it to 1 abolishes all templates, but setting it just
  below 1 to $P=0.99999$ increases the yield to 6 templates with 4.4
  kb. The reason for this is, presumably, that with $P=0.99999$ the
  unique intervals returned by the sliding window analysis are shorter
  than with the default $P$-value, and shorter sequences stand a better
  chance of being found as exact matches in all targets.

  To test this, repeat the analysis with a window of 250 bp instead of
  the default 500 bp. This returns 32 sequences with 12.7 kb.
#+end_src
#+begin_src sh <<Refine tutorial analysis>>=
  fur -d furDb -p 0.99999 -w 250 > tmpl.fasta
  # Step                    Sequences  Nucleotides
  # ----------------------------------------------
  # Sliding window                656       464175
  # Presence in targets            32        12700
  # Absence from neighbors         32        12700
#+end_src
#+begin_src latex
  Now, what happens if the window length is halved again? This returns
  101 template sequences with a total of 20.6 kb, the largest yield so
  far.
#+end_src
#+begin_src sh <<Refine tutorial analysis>>=
  fur -d furDb -p 0.99999 -w 125 > tmpl.fasta
  # Step                    Sequences  Nucleotides
  # ----------------------------------------------
  # Sliding window               1249       337360
  # Presence in targets           101        20636
  # Absence from neighbors        101        20636
#+end_src
#+begin_src latex
  So it might well be worth testing different window lengths
  (\texttt{-w}), alignment lengths (\texttt{-l}), percent identity
  (\texttt{-i}), and $P$-values (\texttt{-p}) in other analyses. This
  can be done conveniently because each run of \texttt{fur} takes only a
  few seconds once the underlying database has been computed.
  \section{List of code chunks}
  \nowebchunks
#+end_src
