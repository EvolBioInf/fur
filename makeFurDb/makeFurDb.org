#+begin_export latex
\section{Introduction}
The program \ty{makeFurDb} takes as input a directory of target files
and a directory of neighbor files. From these two directories it
constructs a third, the \ty{fur} database. This ``database'' is then
analyzed with \ty{fur} to discover regions common to the targets that
are absent from the neighbors. The strategy for finding these regions
is described in the Introduction and summarized there in
steps~(\ref{eq:fur1}) to (\ref{eq:fur3}). To enable \ty{fur} to carry
out these steps, \ty{makeFurDb} fills the database with six elements,
\begin{enumerate}
\item a file containing the program version, \ty{v.txt}
\item a file containing the target sequence on which the search for
  diagnostic markers is centered, the target representative,
  \ty{r.fasta}
\item a directory containing all targets minus the target
  representative, \ty{t/}
\item a file containing the end positions of the match factors of the
  target representative, \ty{e.fasta}
\item a Blast database of the neighbors, \ty{n}
\item a file containing the combined length of the neighbor sequences
  and their GC content, \ty{n.txt}
\end{enumerate}
The implementation of \ty{makeFurDb} is structured along the
construction of these six database parts.

\section{Implementation}
Our outline of \ty{makeFurDb} contains hooks for imports, functions,
and the logic of the main function.  \bpr{makeFurDb}{pr:mfd}
#+end_export
#+begin_src go <<makeFurDb.go>>=
  package main

  import (
	  //<<Imports, Pr. \ref{pr:mfd}>>
  )
  //<<Functions, Pr. \ref{pr:mfd}>>
  func main() {
	  //<<Main function, Pr. \ref{pr:mfd}>>
  }
#+end_src
#+begin_export latex
\epr In the main function we prepare the error handling, declare the
options, set the usage, parse the options, and construct the \ty{fur}
database.
#+end_export
#+begin_src go <<Main function, Pr. \ref{pr:mfd}>>=
  //<<Prepare error handling, Pr. \ref{pr:mfd}>>
  //<<Declare options, Pr. \ref{pr:mfd}>>
  //<<Set usage, Pr. \ref{pr:mfd}>>
  //<<Parse options, Pr. \ref{pr:mfd}>>
  //<<Construct \ty{fur} database, Pr. \ref{pr:mfd}>>
#+end_src
#+begin_export latex
We prepare error handling by calling the utility function
\ty{PrepareErrorMessages}.
#+end_export
#+begin_src go <<Prepare error handling, Pr. \ref{pr:mfd}>>=
  util.PrepareErrorMessages("makeFurDb")
#+end_src
#+begin_src latex
  We declare options for printing the version, for picking the
  directories holding the targets, the neighbors, and the database, for
  picking the target representative, for allowing an existing
  database to be overwritten, and for the number of threads.
#+end_src
#+begin_src go <<Declare options, Pr. \ref{pr:mfd}>>=
  optV := flag.Bool("v", false, "version")
  optT := flag.String("t", "", "target directory")
  optN := flag.String("n", "", "neighbor directory")
  optD := flag.String("d", "", "database directory")
  optR := flag.String("r", "", "target representative " +
	  "(default shortest)")
  optO := flag.Bool("o", false, "overwrite existing database")
  optTT := flag.Int("T", 0, "threads (default logical CPUs)")
#+end_src
#+begin_src latex
  We import \ty{flag}.
#+end_src
#+begin_src go <<Imports, Pr. \ref{pr:mfd}>>=
  "flag"
#+end_src
#+begin_export latex
The coordinates returned by a \ty{fur} analysis are with respect to
the target representative stored in \ty{r.fasta}. However, they will
usually be read as being with respect to the original target
representative submitted by the user. By default, \ty{makeFurDb} sets
nucleotides to upper case and then removes any character that isn't
\ty{A}, \ty{C}, \ty{G}, or \ty{T}. In most cases these non-canonical
nucleotides are stretches of \ty{N}s, which cannot be used in primer
design, the original purpose of Fur. 

The disadvantage of removing non-canonical nucleotides is that this
can lead to differences between the coordinates in \ty{r.fasta} and
its original. Annotations like genes are given with respect to this
original, so we also add an option for keeping non-canonical
nucleotides.
#+end_export
#+begin_src go <<Declare options, Pr. \ref{pr:mfd}>>=
  optK := flag.Bool("k", false, "keep non-canonical nucleotides")
#+end_src
#+begin_export latex
By default streaming skips the length of the matching prefix. However,
the user can set a different skipping fraction.
#+end_export
#+begin_src go <<Declare options, Pr. \ref{pr:mfd}>>=
  optS := flag.Float64("s", 1, "skip by fraction of match")
#+end_src
#+begin_export latex
The usage consists of three parts, the actual usage message, an
explanation of the purpose of \ty{makeFurDb}, and an example command.
#+end_export
#+begin_src go <<Set usage, Pr. \ref{pr:mfd}>>=
  u := "makeFurDb [option]... -t <targetDir> " +
	  "-n <neighborDir> -d <db>"
  p := "Construct fur database."
  e := "makeFurDb -t targets/ -n neighbors/ -d fur.db"
  clio.Usage(u, p, e)
#+end_src
#+begin_export latex
We import \ty{clio}.
#+end_export
#+begin_src go <<Imports, Pr. \ref{pr:mfd}>>=
  "github.com/evolbioinf/clio"
#+end_src
#+begin_export latex
We parse the options and respond to the version option, \ty{-v}, 
the three directory options, \ty{-t}, \ty{-n}, \ty{-d}, and the
threads option, \ty{-T}.
#+end_export
#+begin_src go <<Parse options, Pr. \ref{pr:mfd}>>=
  flag.Parse()
  //<<Respond to \ty{-v}, Pr. \ref{pr:mfd}>>
  //<<Respond to \ty{-t}, Pr. \ref{pr:mfd}>>
  //<<Respond to \ty{-n}, Pr. \ref{pr:mfd}>>
  //<<Respond to \ty{-d}, Pr. \ref{pr:mfd}>>
  //<<Respond to \ty{-T}, Pr. \ref{pr:mfd}>>
#+end_src
#+begin_export latex
If the user requested the version, we call the utility function
\ty{PrintInfo} with the program name.
#+end_export
#+begin_src go <<Respond to \ty{-v}, Pr. \ref{pr:mfd}>>=
  if *optV {
	  util.PrintInfo("makeFurDb")
  }
#+end_src
#+begin_export latex
We import \ty{util}.
#+end_export
#+begin_src go <<Imports, Pr. \ref{pr:mfd}>>=
  "github.com/evolbioinf/fur/util"
#+end_src
#+begin_export latex
If the user didn't set a targets directory, we exit with a friendly
message.
#+end_export
#+begin_src go <<Respond to \ty{-t}, Pr. \ref{pr:mfd}>>=
  if *optT == "" {
	  m := "please provide a directory " +
		  "of target sequences"
	  fmt.Fprintf(os.Stderr, "%s\n", m)
	  os.Exit(1)
  }
#+end_src
#+begin_export latex
We import \ty{fmt} and \ty{os}.
#+end_export
#+begin_src go <<Imports, Pr. \ref{pr:mfd}>>=
  "fmt"
  "os"
#+end_src
#+begin_export latex
We do the same if the user didn't set a neighbors directory.
#+end_export
#+begin_src go <<Respond to \ty{-n}, Pr. \ref{pr:mfd}>>=
  if *optN == "" {
	  m := "please provide a directory " +
		  "of neighbor sequences"
	  fmt.Fprintf(os.Stderr, "%s\n", m)
	  os.Exit(1)
  }
#+end_src
#+begin_export latex
The database directory is the last directory the user needs to set. If
the user failed to do so, we abort with a friendly message. If, on the
other hand, the user named an existing database, we deal with it. At
the end we construct the empty database directory that we fill in the
following sections.
#+end_export
#+begin_src go <<Respond to \ty{-d}, Pr. \ref{pr:mfd}>>=
  if *optD == "" {
	  m := "please provide a database name"
	  fmt.Fprintf(os.Stderr, "%s\n", m)
	  os.Exit(1)
  } else {
	  _, err := os.Stat(*optD)
	  if err == nil {
		  //<<Deal with existing database, Pr. \ref{pr:mfd}>>
	  }
	  err = os.Mkdir(*optD, 0750)
	  util.Check(err)
  }

#+end_src
#+begin_export latex
If the user left the number of threads unspecified, we set it to the
number of logical CPUs.
#+end_export
#+begin_src go <<Respond to \ty{-T}, Pr. \ref{pr:mfd}>>=
  if *optTT == 0 {
	  (*optTT) = runtime.NumCPU()
  }
#+end_src
#+begin_export latex
We import \ty{runtime}.
#+end_export
#+begin_src go <<Imports, Pr. \ref{pr:mfd}>>=
  "runtime"
#+end_src
#+begin_export latex
If the user allowed the database to be overwritten, we remove
it. Otherwise, we bail with a friendly message.
#+end_export
#+begin_src go <<Deal with existing database, Pr. \ref{pr:mfd}>>=
  if *optO {
	  err := os.RemoveAll(*optD)
	  util.Check(err)
  } else {
	  m := fmt.Sprintf("database %s already exists", *optD)
	  fmt.Fprintf(os.Stderr, "%s\n", m)
	  os.Exit(1)
  }
#+end_src
#+begin_export latex
To construct the \ty{fur} database, we read the names of the targets
and neighbors and make sure the two lists don't overlap. This is best
done by storing the names of the targets and neighbors in
maps. However, map keys are accessed randomly. To impose order on
them, we sort the names before making sure they don't overlap. Then we
construct the six elements of the \ty{fur} database to store the
version, the target representative, $r$, the other targets, the ends
of matches, the blast database of neighbors, and the statistics of the
neighbor sequences. These statistics are later used by \ty{fur} to
calculate the null distribution of match lengths.
#+end_export
#+begin_src go <<Construct \ty{fur} database, Pr. \ref{pr:mfd}>>=
  //<<Read names of targets and neighbors, Pr. \ref{pr:mfd}>>
  //<<Sort names of targets and neighbors, Pr. \ref{pr:mfd}>>
  //<<Do targets and neighbors overlap? Pr. \ref{pr:mfd}>>
  //<<Write version to \ty{v.txt}, Pr. \ref{pr:mfd}>>
  //<<Write $r$ to \ty{r.fasta}, Pr. \ref{pr:mfd}>>
  //<<Write the other targets to \ty{t/}, Pr. \ref{pr:mfd}>>
  //<<Write match ends to \ty{e.fasta}, Pr. \ref{pr:mfd}>>
  //<<Write Blast database of neighbors to \ty{n}, Pr. \ref{pr:mfd}>>
  //<<Write statistics of neighbors to \ty{n.txt}, Pr. \ref{pr:mfd}>>
#+end_src
#+begin_export latex
We delegate reading the names of the targets and neighbors to the
function \ty{readDir}. If either of these directories is empty, we
bail with a friendly message.
#+end_export
#+begin_src go <<Read names of targets and neighbors, Pr. \ref{pr:mfd}>>=
  targets := readDir(*optT)
  if len(targets) == 0 {
	  fmt.Fprintf(os.Stderr, "%s is empty\n", *optT)
	  os.Exit(1)
  }
  neighbors := readDir(*optN)
  if len(neighbors) == 0 {
	  fmt.Fprintf(os.Stderr, "%s is empty\n", *optN)
	  os.Exit(1)
  }
#+end_src
#+begin_export latex
The function \ty{readDir} takes as input the name of a directory and
returns a map of the names of the sequence files contained in the
directory. We check each directory entry before storing its name.
#+end_export
#+begin_src go <<Functions, Pr. \ref{pr:mfd}>>=
  func readDir(dir string) map[string]bool {
	  dirEntries, err := os.ReadDir(dir)
	  util.Check(err)
	  names := make(map[string]bool)
	  for _, dirEntry := range dirEntries {
		  //<<Check directory entry, Pr. \ref{pr:mfd}>>
		  names[dirEntry.Name()] = true
	  }
	  return names
  }
#+end_src
#+begin_export latex
A directory entry should be a file rather than a subdirectory. Given
that it is indeed a file, it should also be a nucleotide FASTA file.
#+end_export
#+begin_src go <<Check directory entry, Pr. \ref{pr:mfd}>>=
  //<<Is the directory entry a file? Pr. \ref{pr:mfd}>>
  //<<Is the directory entry a nucleotide file? Pr. \ref{pr:mfd}>>
#+end_src
#+begin_export latex
If the directory entry is a subdirectory, we warn the user and skip
it.
#+end_export
#+begin_src go <<Is the directory entry a file? Pr. \ref{pr:mfd}>>=
  if dirEntry.IsDir() {
	  p := dir + "/" + dirEntry.Name()
	  fmt.Fprintf(os.Stderr,
		  "skipping subdirectory %s\n", p)
	  continue
  }
#+end_src
#+begin_export latex
There are five filename extensions that denote nucleotide FASTA files
listed on
Wikipedia\footnote{\ty{https://en.wikipedia.org/wiki/FASTA\_format}},
\ty{.fasta}, \ty{.fna}, \ty{.ffn}, \ty{.frn}, and \ty{.fa}. If the
file has a different extension or none, we skip it and send a warning.
#+end_export
#+begin_src go <<Is the directory entry a nucleotide file? Pr. \ref{pr:mfd}>>=
  ext := filepath.Ext(dirEntry.Name())
  if ext != ".fasta" && ext != ".fna" && ext != ".ffn" &&
	  ext != ".frn" && ext != ".fa" {
	  m := "%s doesn't have the extension of " +
		  "a nucleotide FASTA file; skipping it\n"
	  p := dir + "/" + dirEntry.Name()
	  fmt.Fprintf(os.Stderr, m, p)
	  continue
  }
#+end_src
#+begin_export latex
We import \ty{filepath}.
#+end_export
#+begin_src go <<Imports, Pr. \ref{pr:mfd}>>=
  "path/filepath"
#+end_src
#+begin_export latex
We store the names of the neighbors and targets in slices and sort
them.
#+end_export
#+begin_src go <<Sort names of targets and neighbors, Pr. \ref{pr:mfd}>>=
  var targetNames, neighborNames []string
  for target := range targets {
	  targetNames = append(targetNames, target)
  }
  sort.Strings(targetNames)
  for neighbor := range neighbors {
	  neighborNames = append(neighborNames, neighbor)
  }
  sort.Strings(neighborNames)
#+end_src
#+begin_export latex
We import \ty{sort}.
#+end_export
#+begin_src go <<Imports, Pr. \ref{pr:mfd}>>=
  "sort"
#+end_src
#+begin_export latex
A common error when searching for markers is to include a sequence
file in both the target and the neighbor set. To guard against this,
we search for pairs of repeated file names and bail with message if we
find one.
#+end_export
#+begin_src go <<Do targets and neighbors overlap? Pr. \ref{pr:mfd}>>=
  for _, target := range targetNames {
	  if neighbors[target] {
		  m := "found %s/%s and %s/%s; please " +
			  "make sure the targets and " +
			  "neighbors don't overlap"
		  fmt.Fprintf(os.Stderr, m, *optT,
			  target, *optN, target)
		  os.Exit(1)
	  }
  }
#+end_src
#+begin_export latex
\subsection{Version File, \ty{v.txt}}
To construct the version file, we open \ty{v.txt} inside the database,
write the version to it, and close it again.
#+end_export
#+begin_src go <<Write version to \ty{v.txt}, Pr. \ref{pr:mfd}>>=
  vf := *optD + "/v.txt"
  f, err := os.Create(vf)
  util.Check(err)
  fmt.Fprintf(f, "%s\n", util.Version())
  f.Close()
#+end_src
#+begin_export latex
\subsection{Target Representative, \ty{r.fasta}}
If the user didn't set a target representative, we need to pick
one. In any case, we report which target is used as
representative. Then we store the target sequences and write them to
file.
#+end_export
#+begin_src go <<Write $r$ to \ty{r.fasta}, Pr. \ref{pr:mfd}>>=
  if *optR == "" {
	  //<<Pick target representative, Pr. \ref{pr:mfd}>>
  }
  fmt.Fprintf(os.Stderr, "using %s as target representative\n",
	  (*optR))
  rep := *optT + "/" + *optR
  //<<Store $r$, Pr. \ref{pr:mfd}>>
  //<<Write $r$, Pr. \ref{pr:mfd}>>
#+end_src
#+begin_export latex
By default, the target representative is the shortest target
sequence. To pick it, we iterate over the target files, calculate
their lengths, and store the name of the shortest target found so far
and its length. At the end we store the name of the overall shortest
target.
#+end_export
#+begin_src go <<Pick target representative, Pr. \ref{pr:mfd}>>=
  minTar := ""
  minLen := math.MaxInt
  for target, _ := range targets {
	  l := 0
	  //<<Calculate length of target sequence, Pr. \ref{pr:mfd}>>
	  if l < minLen {
		  minTar = target
		  minLen = l
	  }
  }
  (*optR) = minTar
#+end_src
#+begin_export latex
We import \ty{math}.
#+end_export
#+begin_src go <<Imports, Pr. \ref{pr:mfd}>>=
  "math"
#+end_src
#+begin_export latex
We iterate over the entries in the current target file and sum their
lengths.
#+end_export
#+begin_src go <<Calculate length of target sequence, Pr. \ref{pr:mfd}>>=
  p := *optT + "/" + target
  f, err := os.Open(p)
  util.Check(err)
  defer f.Close()
  sc := fasta.NewScanner(f)
  for sc.ScanSequence() {
	  l += len(sc.Sequence().Data())
  }
#+end_src
#+begin_export latex
We import \ty{fasta}.
#+end_export
#+begin_src go <<Imports, Pr. \ref{pr:mfd}>>=
  "github.com/evolbioinf/fasta"
#+end_src
#+begin_export latex
We open the file containing $r$, iterate over its sequences, clean
them, and store them.
#+end_export
#+begin_src go <<Store $r$, Pr. \ref{pr:mfd}>>=
  f, err = os.Open(rep)
  util.Check(err)
  defer f.Close()
  var repSeqs []*fasta.Sequence
  sc := fasta.NewScanner(f)
  for sc.ScanSequence() {
	  seq := sc.Sequence()
	  //<<Clean sequence, Pr. \ref{pr:mfd}>>
	  repSeqs = append(repSeqs, seq)
  }
#+end_src
#+begin_export latex
Cleaning consists of setting the sequence data to upper case. We also
remove non-canonical nucleotides, unless the user opted to keep
them. In the last cleaning step we reduce the header to the first
token, usually the accession. This ensures that there are no blanks in
the names of the sequences later passed to Blast.
#+end_export
#+begin_src go <<Clean sequence, Pr. \ref{pr:mfd}>>=
  d := bytes.ToUpper(seq.Data())
  if !*optK {
	  //<<Remove non-canonical nucleotides, Pr. \ref{pr:mfd}>>
  }
  h := strings.Fields(seq.Header())[0]
  seq = fasta.NewSequence(h, d)
#+end_src
#+begin_export latex
We import \ty{bytes} and \ty{strings}.
#+end_export
#+begin_src go <<Imports, Pr. \ref{pr:mfd}>>=
  "bytes"
  "strings"
#+end_src
#+begin_export latex
We remove the non-canonical bases using reslicing.
#+end_export
#+begin_src go <<Remove non-canonical nucleotides, Pr. \ref{pr:mfd}>>=
  i := 0
  for _, c := range d {
	  if c == 'A' || c == 'C' || c == 'G' || c == 'T' {
		  d[i] = c
		  i++
	  }
  }
  d = d[:i]
#+end_src
#+begin_export latex
We write $r$ to \ty{r.fasta}.
#+end_export
#+begin_src go <<Write $r$, Pr. \ref{pr:mfd}>>=
  dest := *optD + "/r.fasta"
  w, err := os.Create(dest)
  util.Check(err)
  defer w.Close()
  for _, repSeq := range repSeqs {
	  fmt.Fprintf(w, "%s\n", repSeq)
  }
#+end_src
#+begin_export latex
\subsection{Target Directory, \ty{t/}}
We copy the targets minus the representative to the directory \ty{t}
inside the database.
#+end_export
#+begin_src go <<Write the other targets to \ty{t/}, Pr. \ref{pr:mfd}>>=
  p = *optD + "/t/"
  err = os.Mkdir(p, 0750)
  util.Check(err)
  for target, _ := range targets {
	  if target == *optR { continue }
	  source := *optT + "/" + target
	  dest := *optD + "/t/" + target
	  sd, err := os.ReadFile(source)
	  util.Check(err)
	  err = os.WriteFile(dest, sd, 0666)
  }
#+end_src
#+begin_export latex
\subsection{Match Ends, \ty{e.fasta}}
The match ends are calculated from the ESA of $r$
(Algorithm~\ref{alg:nml}, line 1). The ESA is used to calculate the
match lengths between $r$ and the neighbors by streaming the neighbors
against $r$ (Algorithm~\ref{alg:nml}, lines 2--14). We convert these
match lengths to match ends and write them to file.
\begin{algorithm}
  \caption{Computing match lengths between $r$ and neighborhood.}\label{alg:nml}
  \begin{algorithmic}[1]
    \input{../makeFurDb/newMlAlg}
  \end{algorithmic}
\end{algorithm}
#+end_export
#+begin_src go <<Write match ends to \ty{e.fasta}, Pr. \ref{pr:mfd}>>=
  //<<Calculate ESA of $r$, Pr. \ref{pr:mfd}>>
  //<<Calculate match lengths, Pr. \ref{pr:mfd}>>
  //<<Convert match lengths to match ends, Pr. \ref{pr:mfd}>>
  //<<Write match ends, Pr. \ref{pr:mfd}>>
#+end_src
#+begin_export latex
We concatenate the sequences of the target rep and calculate the ESA
of the resulting single sequence.
#+end_export
#+begin_src go <<Calculate ESA of $r$, Pr. \ref{pr:mfd}>>=
  var r []byte
  for _, repSeq := range repSeqs {
	  r = append(r, repSeq.Data()...)
  }
  resa := esa.MakeEsa(r)
#+end_src
#+begin_export latex
We import \ty{esa}.
#+end_export
#+begin_src go <<Imports, Pr. \ref{pr:mfd}>>=
  "github.com/evolbioinf/esa"
#+end_src
#+begin_export latex
The match lengths are calculated by streaming all neighbor sequences
against the ESA of $r$. We distribute the streaming work along sets of
neighbor files, which we construct first. Then we concurrently stream
the sets of neighbor sequences against the target representative. For
this we use the concurrency pattern based on a \ty{sync.WaitGroup},
which we can think of as a counter of working goroutines
\cite[p. 237ff]{don16:go}. This concurrency pattern is built from a
channel and a \ty{WaitGroup}, both of which we initialize outside of
the loop in which we spawn the goroutines. The channel,
\ty{matchLengths}, allows us to pass a slice of match lengths out of
the goroutine in which it was filled in. Inside the loop we increment
the counter of the working goroutines and construct the goroutine for
streaming. After the loop, we construct the closer and iterator that
are also part of the \ty{WaitGroup} concurrency pattern, as
illustrated in Figure~8.5 of \cite[p. 239]{don16:go}.

The results of the myriad matching operations need to be merged at the
end to get the desired match lengths.
#+end_export
#+begin_src go <<Calculate match lengths, Pr. \ref{pr:mfd}>>=
  neighborNameSets := make([][]string, 0)
  //<<Construct neighbor name sets, Pr. \ref{pr:mfd}>>
  matchLengths := make(chan []int)
  var wg sync.WaitGroup
  for _, neighborNames := range neighborNameSets {
	  wg.Add(1)
	  //<<Goroutine for streaming, Pr. \ref{pr:mfd}>>
  }
  //<<Streaming closer, Pr. \ref{pr:mfd}>>
  //<<Streaming iterator, Pr. \ref{pr:mfd}>>
  //<<Merge match lengths, Pr. \ref{pr:mfd}>>
#+end_src
#+begin_export latex
We import \ty{sync}.
#+end_export
#+begin_src go <<Imports, Pr. \ref{pr:mfd}>>=
  "sync"
#+end_src
#+begin_export latex
Given $n$ neighbor files and $T$ threads, we construct a slice of file
names and split it into slices of length $\ell=n/T$.
#+end_export
#+begin_src go <<Construct neighbor name sets, Pr. \ref{pr:mfd}>>=
  n := len(neighbors)
  length := int(math.Ceil(float64(n)/float64(*optTT)))
  names := make([]string, n)
  //<<Construct names slice, Pr. \ref{pr:mfd}>>
  start := 0
  end := length
  //<<Split names, Pr. \ref{pr:mfd}>>
#+end_src
#+begin_export latex
We import \ty{math}.
#+end_export
#+begin_src go <<Import, Pr. \ref{pr:mfd}>>=
  "math"
#+end_src
#+begin_export latex
We split the names into slices of length $\ell$ and make sure we also
include the remaining names.
#+end_export
#+begin_src go <<Split names, Pr. \ref{pr:mfd}>>=
  for start < n && end <= n {
	  neighborNameSets = append(neighborNameSets,
		  names[start:end])
	  start = end
	  end += length
  }
  if end < n {
	  neighborNameSets = append(neighborNameSets,
		  names[start:])
  }
#+end_src
#+begin_export latex
We iterate over the names of neighbor files. The order in which we do
this is random, which is a good thing as files might be initially be
ordered by size. Such an ordering would unbalance the load of the
threads for streaming.
#+end_export
#+begin_src go <<Construct names slice, Pr. \ref{pr:mfd}>>=
  k := 0
  for name, _ := range neighbors {
	  names[k] = name
	  k++
  }
#+end_src
#+begin_export latex
We pass the current set of neighbor names to the goroutine. Inside the
routine, we make sure its eventual end is signaled to the
\ty{WaitGroup}. We also allocate space for the match lengths, stream
the neighbors against $r$, and pass the resulting match lengths along
the channel.
#+end_export
#+begin_src go <<Goroutine for streaming, Pr. \ref{pr:mfd}>>=
  go func(neighborNames []string) {
	  defer wg.Done()
	  ml := make([]int, len(resa.T))
	  //<<Stream neighbors against $r$, Pr. \ref{pr:mfd}>>
	  matchLengths <- ml
  }(neighborNames)
#+end_src
#+begin_export latex
In the streaming step we iterate over the neighbor files. For each
file, we iterate over the sequences it contains, as shown in line 2 of
Algorithm~\ref{alg:nml}.
#+end_export
#+begin_src go <<Stream neighbors against $r$, Pr. \ref{pr:mfd}>>=
  for _, neighbor := range neighborNames {
	  p := *optN + "/" + neighbor
	  f, err := os.Open(p)
	  util.Check(err)
	  defer f.Close()
	  //<<Interate over neighbor sequences, Pr. \ref{pr:mfd}>>
  }
#+end_src
#+begin_export latex
For each neighbor sequence, we stream the forward and the reverse
strand against $r$ by calling the function \ty{streamSeq}.
#+end_export
#+begin_src go <<Interate over neighbor sequences, Pr. \ref{pr:mfd}>>=
  sc := fasta.NewScanner(f)
  for sc.ScanSequence() {
	  nei := sc.Sequence()
	  streamSeq(nei.Data(), resa, ml, optS)
	  nei.ReverseComplement()
	  streamSeq(nei.Data(), resa, ml, optS)
  }
#+end_src
#+begin_export latex
Inside the function \ty{streamSeq} we match successive prefixes of the
current neighbor sequence, $n_i$, against $r$. As stated in line 5 of
Algorithm~\ref{alg:nml}, matching is carried out by calls to the
function \ty{MatchPrefix}, which is a method of the ESA of $r$. This
method returns an interval of the lcp-interval tree implied by the
ESA. The interval consists of a triplet of numbers, the length of the
match, $\ell$, and the start and end of the interval in the suffix
array. Each element of the interval represents a match position, $p$
in $r$. If we that match is longer than the previous longest, we store
it as shown in lines 7--9 of Algorithm~\ref{alg:nml}. Then we move
advance the match position and repeat.
#+end_export
#+begin_src go <<Functions, Pr. \ref{pr:mfd}>>=
  func streamSeq(ni []byte, resa *esa.Esa, ml []int, optS *float64) {
	  for j := 0; j < len(ni); {
		  m := resa.MatchPref(ni[j:])
		  for k := m.I; k <= m.J; k++ {
			  p := resa.Sa[k]
			  if ml[p] < m.L {
				  ml[p] = m.L
			  }
		  }
		  //<<Advance match position, Pr. \ref{pr:mfd}>>
	  }
  }
#+end_src
#+begin_export latex
We advance by the skip fraction of the match and make sure we advance
by at least one nucleotide.
#+end_export
#+begin_src go <<Advance match position, Pr. \ref{pr:mfd}>>=
  j += m.L + 1
#+end_src
#+begin_export latex
In the closer we wait until all working goroutines have finished and
then close the channel for passing match
lengths~\cite[p. 238]{don16:go}.
#+end_export
#+begin_src go <<Streaming closer, Pr. \ref{pr:mfd}>>=
  go func() {
	  wg.Wait()
	  close(matchLengths)
  }()
#+end_src
#+begin_export latex
The iterator that drives the goroutines picks match lengths off the
channel, which we combine into a master slice of match lengths.
#+end_export
#+begin_src go <<Streaming iterator, Pr. \ref{pr:mfd}>>=
  ml := make([]int, len(resa.T))
  for mls := range matchLengths {
	  for i, l := range mls {
		  if ml[i] < l {
			  ml[i] = l
		  }
	  }
  }
#+end_src
#+begin_export latex
The match lengths we've now recorded in $\mathrm{ml}$ are lengths of
matches in $r$ noted at their starting positions. We merge these match
lengths by also entering the implied lengths, i. e. we make sure that
\[
\mbox{ml}[i]\ge\mbox{ml}[i-1]-1
\]
We also make sure that the minimum match length is 1, which means we
always advance when skipping across match factors.
#+end_export
#+begin_src go <<Merge match lengths, Pr. \ref{pr:mfd}>>=
  if ml[0] == 0 {
	  ml[0] = 1
  }
  for i := 1; i < len(ml); i++ {
	  if ml[i] < ml[i-1] - 1 {
		  ml[i] = ml[i-1] - 1
	  }
	  if ml[i] <= 0 {
		  ml[i] = 1
	  }
  }
#+end_src
#+begin_export latex
We convert the match lengths to match ends by noting the match ends
implied by the match lengths as \ty{1}, all other positions as \ty{0}.
#+end_export
#+begin_src go <<Convert match lengths to match ends, Pr. \ref{pr:mfd}>>=
  ends := make([]byte, len(resa.T))
  for i := 0; i < len(resa.T); i++ {
	  ends[i] = '0'
  }
  for i := 0; i < len(resa.T); {
	  p := i + ml[i] - 1
	  ends[p] = '1'
	  i += ml[i] + 1
  }
#+end_src
#+begin_export latex
We iterate over the sequences that make up $r$ and write the
corresponding sequences of zeros and ones.
#+end_export
#+begin_src go <<Write match ends, Pr. \ref{pr:mfd}>>=
  f, err = os.Create(*optD + "/e.fasta")
  util.Check(err)
  defer f.Close()
  start = 0
  for _, repSeq := range repSeqs {
	  //<<Create end sequence, Pr. \ref{pr:mfd}>>
	  //<<Write end sequence, Pr. \ref{pr:mfd}>>
  }
#+end_src
#+begin_export latex
The end sequence has the length of the current sequence from $r$.
#+end_export
#+begin_src go <<Create end sequence, Pr. \ref{pr:mfd}>>=
  end := start + len(repSeq.Data())
  eseq := fasta.NewSequence(repSeq.Header(), ends[start:end])
  start = end
#+end_src
#+begin_export latex
We write the new sequence of ends to file.
#+end_export
#+begin_src go <<Write end sequence, Pr. \ref{pr:mfd}>>=
  fmt.Fprintf(f, "%s\n", eseq)
#+end_src
#+begin_export latex
\subsection{Blast Database of Neighbors, \ty{n}}
We come to the last element of the \ty{fur} database, the Blast
database of the neighbors. To construct this, we run the external
program \ty{makeblastdb} and pipe the neighbor sequences to it. At
this point we visit every neighbor sequence. So we take the
opportunity to also count the total number of nucleotides they
contain, $l$, and the number of \ty{C}s and \ty{G}s, $g$. These values
are later used in \ty{fur} to calculate the null distribution of match
lengths.
#+end_export
#+begin_src go <<Write Blast database of neighbors to \ty{n}, Pr. \ref{pr:mfd}>>=
  fmt.Fprintf(os.Stderr, "making Blast database\n")
  cmd := exec.Command("makeblastdb", "-dbtype", "nucl",
	  "-out", *optD + "/n", "-title", "t")
  stdin, err := cmd.StdinPipe()
  util.Check(err)
  var l, g int
  go func() {
	  defer stdin.Close()
	  //<<Pipe neighbors to \ty{makeblastdb}, Pr. \ref{pr:mfd}>>
  }()
  _, err = cmd.Output()
  util.Check(err)
#+end_src
#+begin_export latex
We import \ty{exec}.
#+end_export
#+begin_src go <<Imports, Pr. \ref{pr:mfd}>>=
  "os/exec"
#+end_src
#+begin_export latex
We iterate over the sequences in each neighbor file and print each
sequence to the destination file. We also count the total number of
nucleotides, $l$, and the combined number of \ty{G} and \ty{C}, $g$.
#+end_export
#+begin_src go <<Pipe neighbors to \ty{makeblastdb}, Pr. \ref{pr:mfd}>>=
  for neighbor, _ := range neighbors {
	  p := *optN + "/" + neighbor
	  r, err := os.Open(p)
	  util.Check(err)
	  sc := fasta.NewScanner(r)
	  for sc.ScanSequence() {
		  seq := sc.Sequence()
		  //<<Update $l$ and $g$, Pr. \ref{pr:mfd})>>
		  fmt.Fprintf(stdin, "%s\n", seq)
	  }
  }
#+end_src
#+begin_export latex
We scan across the sequence data to count the residues.
#+end_export
#+begin_src go <<Update $l$ and $g$, Pr. \ref{pr:mfd})>>=
  d := bytes.ToUpper(seq.Data())
  for _, c := range d {
	  if c == 'A' || c == 'C' || c == 'G' || c == 'T' {
		  l++
		  if c == 'C' || c == 'G' {
			  g++
		  }
	  }
  }
#+end_src
#+begin_export latex
\subsection{Neighbor Statistics, \ty{n.txt}}
We write the number of nucleotides and the GC content to file.
#+end_export
#+begin_src go <<Write statistics of neighbors to \ty{n.txt}, Pr. \ref{pr:mfd}>>=
  w, err = os.Create(*optD + "/n.txt")
  util.Check(err)
  gc := float64(g) / float64(l)
  fmt.Fprintf(w, "length: %d\nGC-content: %f\n", l, gc)
  w.Close()
#+end_src
#+begin_export latex
We are done with \ty{makeFurDb}, time to test it.
\section{Testing}
Our program to test \ty{makeFurDb} has hooks for imports and the
testing logic.
#+end_export
#+begin_src go <<makeFurDb_test.go>>=
  package main

  import (
	  "testing"
	  //<<Testing imports, Pr. \ref{pr:mfd}>>
  )

  func TestMakeFurDb(t *testing.T) {
	  //<<Testing, Pr. \ref{pr:mfd}>>
  }
#+end_src
#+begin_export latex
We construct a set of tests and iterate over them.
#+end_export
#+begin_src go <<Testing, Pr. \ref{pr:mfd}>>=
  var tests []*exec.Cmd
  //<<Construct tests, Pr. \ref{pr:mfd}>>
  for i, test := range tests {
	  //<<Run test, Pr. \ref{pr:mfd}>>
  }
#+end_src
#+begin_export latex
We import \ty{exec}.
#+end_export
#+begin_src go <<Testing imports, Pr. \ref{pr:mfd}>>=
  "os/exec"
#+end_src
#+begin_export latex
Our first test is a run with default options, where we only set the
targets, neighbors and the database. We also allow the database to be
overwritten.
#+end_export
#+begin_src go <<Construct tests, Pr. \ref{pr:mfd}>>=
  p := "./makeFurDb"
  a := "targets"
  n := "neighbors"
  d := "test.db"
  test := exec.Command(p, "-t", a, "-n", n, "-d", d, "-o")
  tests = append(tests, test)
#+end_src
#+begin_export latex
In our second test we also pick \ty{t2.fasta} as the target
representative.
#+end_export
#+begin_src go <<Construct tests, Pr. \ref{pr:mfd}>>=
  r := "t2.fasta"
  test = exec.Command(p, "-t", a, "-n", n, "-d", d, "-o",
	  "-r", r)
  tests = append(tests, test)
#+end_src
#+begin_export latex
In our third test we also set the skipping fraction to half the match
length.
#+end_export
#+begin_src go <<Construct tests, Pr. \ref{pr:mfd}>>=
  test = exec.Command(p, "-t", a, "-n", n, "-d", d, "-o",
	  "-r", r, "-s", "0.5")
  tests = append(tests, test)
#+end_src
#+begin_export latex
In our fourth and final test we set the skipping to single
nucleotides.
#+end_export
#+begin_src go <<Construct tests, Pr. \ref{pr:mfd}>>=
  test = exec.Command(p, "-t", a, "-n", n, "-d", d, "-o",
	  "-r", r, "-s", "-1")
  tests = append(tests, test)
#+end_src
#+begin_export latex
We run a test and compare the result we get, that is, the ends file
\ty{e.fasta}, with the results we want, which are stored in the files
\ty{r1.txt} and \ty{r2.txt}.
#+end_export
#+begin_src go <<Run test, Pr. \ref{pr:mfd}>>=
  _, err := test.Output()
  if err != nil { t.Error(err) }
  get, err := os.ReadFile(d + "/e.fasta")
  if err != nil { t.Error(err) }
  f := "r" + strconv.Itoa(i+1) + ".txt"
  want, err := os.ReadFile(f)
  if err != nil { t.Error(err) }
  if !bytes.Equal(get, want) {
	  t.Errorf("get:\n%s\nwant:\n%s\n", get, want)
  }
#+end_src
#+begin_export latex
We import \ty{os}, \ty{strconv}, and \ty{bytes}.
#+end_export
#+begin_src go <<Testing imports, Pr. \ref{pr:mfd}>>=
  "os"
  "strconv"
  "bytes"
#+end_src
